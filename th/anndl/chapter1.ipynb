{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### โครงข่ายประสาทเทียมและการเรียนรู้เชิงลึก (์Artificial Neural Networks and Deep Learning)\n",
    "**ดร.วโรดม ตู้จินดา**\n",
    "<br>ภาควิชาวิศวกรรมเครื่องกล มหาวิทยาลัยเกษตรศาสตร์"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### บทที่ 1. บทนำ\n",
    "\n",
    "ก่อนจะเข้าสู่เนื้อหาหลัก เราลองหาคำจำกัดความของการเรียนรู้เชิงลึก (deep learning) เริ่มต้นจากโดเมนใหญ่สุด \n",
    "จากคำบรรยายในวิกิพิเดีย ปัญญาประดิษฐ์ (artificial intelligence) \n",
    "หรือที่นิยมเรียกโดยย่อว่า AI คือเชาว์ปัญญาที่แสดงให้เห็นในเครื่องจักรกล \n",
    "แตกต่างจากปัญญาธรรมชาติจากสมองของมนุษย์หรือสัตว์ ดังนั้น AI จะครอบคลุมนวัตกรรมทั้งหมดที่ทำให้คอมพิวเตอร์มีความชาญฉลาดเข้าสู่ปัญญาของมนุษย์ \n",
    "ซึ่งมีขอบเขตที่กว้างมาก การเรียนรู้ของเครื่อง (machine learning) คือเซตย่อยของเอไอที่เน้นการศึกษาขั้นตอนวิธีทางคอมพิวเตอร์ในการเรียนรู้และปรับตัวจากข้อมูล ซึ่งสามารถทำได้\n",
    "หลายแนวทางเช่นการหาค่าเหมาะที่สุด ทฤษฏีกราฟ แต่ในหนังสือนี้จะศึกษาวิธีการใช้โครงข่ายประสาทเทียม (artificial neural network) ซึ่งต่อไปจะอ้างถึงโดยตัวย่อ \n",
    "ANN ในการเรียนรู้ กล่าวได้ว่า ANN คือระบบคอมพิวเตอร์หรือโมเดลทางคณิตศาสตร์ที่ใช้ในการจำลองสมองทางชีวภาพ โดยอาศัยการเรียนรู้หรือเรียกว่าการฝึก (training) \n",
    "โดยข้อมูลตัวอย่าง เมื่อเขียนภาพรวมความสัมพันธ์ของขอบเขตปัญหาที่กล่าวมาจะได้ดังแสดงในรูปที่ 1.1 \n",
    "\n",
    "<p />  \n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?id=1r_T5zq9MMcGXptpF_k1BU5nfC4Kq6WM_\" width=500 />\n",
    "</p>\n",
    "<div align=\"center\">รูปที่ 1.1 ความสัมพันธ์ของปัญญาประดิษฐ์ การเรียนรู้ของเครื่อง และการเรียนรู้เชิงลึก</div>\n",
    "\n",
    "ความแตกต่างสำคัญระหว่างแนวทางการเรียนรู้ของเครื่องกับการโปรแกรมคอมพิวเตอร์ทั่วไปแสดงได้ในรูปที่ 1.2 แผนภาพด้านบนคือการเขียนโปรแกรมในรูปแบบที่เราคุ้นเคย \n",
    "สมมุติว่าต้องการเขียนฟังก์ชันอย่างง่ายเพื่อบวกเลขสองจำนวน คำสั่งในโปรแกรมคือการดำเนินการบวก และอาจมีการตรวจสอบว่าตัวแปรที่ได้รับเป็นประเภทตัวเลข การดำเนินการและเงื่อนไขเหล่านี้คือกฏของฟังก์ชัน และตัวเลขที่เป็นอาร์กิวเมนต์ของฟังก์ชันคือข้อมูล สิ่งที่คืนค่าจากฟังก์ชันหรือเอาต์พุตก็คือผลลัพธ์ของการบวก\n",
    "ซึ่งจะได้คำตอบเป็นตัวเลข ซึ่งสำหรับฟังก์ชันง่ายๆ นี้อาจมองไม่เห็นปัญหา แต่ลองคิดดูเล่นๆ ว่าถ้าต้องการขยายฟังก์ชันนี้ให้รับอินพุตรูปแบบอื่น เช่นถ้าอินพุตเป็นตัวแปรสตริง\n",
    "ให้ต่อข้อความเข้าด้วยกัน หรืออาจเป็นวัตถุอื่นเช่นมะละกอฝานรวมกับมะเขือเทศเป็นส่วนหนึ่งของส้มตำ กฏของโปรแกรมจะต้องถูกเพิ่มเงื่อนไขมากขึ้นจนในที่สุดมีความซับซ้อนเกินกว่าจะจัดการได้\n",
    "หรืออาจเกิดปัญหา\n",
    "ความขัดแย้งกันระหว่างกฎ พิจารณาอีกตัวอย่างหนึ่งที่เกี่ยวข้องกับ AI มากขึ้น เราต้องการสร้างอุปกรณ์ที่ช่วยผู้พิการในกิจกรรมต่างๆ ในชีวิตประจำวัน ตั้งกฏหนึ่งไว้เพื่อความปลอดภัยว่าของมีคม\n",
    "จะต้องอยู่ไม่ใกล้อวัยวะของผู้ใช้เกินค่าที่กำหนด ผลคืออุปกรณ์นี้ไม่สามารถโกนหนวดให้กับเขาได้เพราะวิเคราะห์ว่าเป็นอันตราย คามขัดแย้งของกฏในลักษณะนี้ทำให้แนวทางปัญญาประดิษฐ์ที่ใช้ระบบ\n",
    "ผู้เชี่ยวชาญ (expert systems) ไม่ประสบความสำเร็จเท่าที่ควรและส่งผลให้การวิจัยในด้านนี้หยุดชะงักไปช่วงเวลาหนึ่ง เรียกกันว่าเป็นช่วงฤดูหนาวของ AI\n",
    "\n",
    "<p />  \n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?id=1xmiNtJjHI7XFxTAI92gqJgbbstC4iDzj\" width=500 />\n",
    "</p>\n",
    "<div align=\"center\">รูปที่ 1.2 ความแตกต่างระหว่างการโปรแกรมทั่วไปกับการเรียนรู้ของเครื่อง</div>\n",
    "\n",
    "เมื่อพิจารณากระบวนทัศน์ของการแก้ปัญหาในแนวทางการเรียนรู้ของเครื่องในแผนภาพด้านล่างของรูปที่ 1.2 จะเห็นว่าอินพุตของระบบคือ\n",
    "ข้อมูลและคำตอบ ซึ่งโดยทั่วไปจะมีจำนวนมากและมีความหลากหลาย คอมพิวเตอร์ใช้อินพุตนี้ในการฝึกฝนตัวเองจนกระทั่งได้กฎที่สอดคล้อง\n",
    "กับความต้องการของผู้ใช้มากที่สุด ตัวอย่างที่มีการใช้งานมากสุดคือการจำแนกภาพ เช่นต้องการจำแนกภาพสัตว์เลี้ยงระหว่างสุนัขกับแมว ข้อมูล\n",
    "สำหรับฝึกคือภาพของสุนัขและแมวในอริยาบทต่างๆ จำนวนมากเพียงพอ และคำตอบของภาพนั้นที่เรียกว่า เลเบล (label) หรือความจริงมูลเหตุ \n",
    "(ground truth) หากการฝึกประสบผลสำเร็จ โมเดลที่ได้จะสามารถจำแนกภาพที่เป็นข้อมูลทดสอบ หรือภาพจากกลัองที่ไม่เคยใช้ในการฝึก \n",
    "โดยมีความแม่นยำขึ้นกับหลายปัจจัยเช่น จำนวนข้อมูลในการฝึก สถาปัตยกรรมของโมเดล ความยากง่ายของภาพที่ต้องการพยากรณ์ การเรียนรู้เชิงลึกโดยใช้ ANN \n",
    "เป็นวิธีการหนึ่งที่ใช้ในปัญหาการจำแนกได้อย่างมีประสิทธิภาพ โดยผลจากการแข่งขันมีความแม่นยำเหนือกว่าแนวทางอื่น ทำให้ AI กลับมาได้รับ\n",
    "ความสนใจอีกครั้งจนถึงปัจจุบัน\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 ประวัติโดยย่อของโครงข่ายประสาทเทียม\n",
    "\n",
    "แท้จริงแล้วการจำลองสมองทางชีวภาพโดย ANN มิใช่เป็นวิธีการใหม่ แต่ได้เริ่มต้นมาตั้งแต่ ค.ศ 1943 โดยนักประสาทวิทยา \n",
    "Warren McCulloch และนักคณิตศาสตร์ Waler Pitts เขียนบทความเกี่ยวกับการทำงานของเซลล์ประสาทที่สามารถสร้างโมเดลจำลองเป็นวงจรไฟฟ้า ต่อมาในปี ค.ศ. \n",
    "1949 Donald Hebb ได้เขียนหนังสือชื่อเรื่อง The Organization of Behavior เสริมแนวคิดการทำงานของเซลล์ประสาท ต่อมาในยุคเริ่มต้นของคอมพิวเตอร์ช่วงทศวรรษ\n",
    "ที่ 1950 เริ่มมีการโมเดลทฤษฎีเหล่านี้และจำลองโครงข่ายประาทเทียมครั้งแรกโดย Nathanial Rochester ณ ห้องปฏิบัติการวิจัยของไอบีเอ็ม ซึ่งไม่ประสบผลสำเร็จ ใน\n",
    "ช่วงเวลาดังกล่าวความสนใจในการโปรแกรมคอมพิวเตอร์เป็นไปในแนวทางดั้งเดิมมีมากกว่า แม้ในปี ค.ศ. 1956 จะเกิดโครงการ Darthmouth Summer Research \n",
    "Project on Artificial Intelligence ที่ช่วยกระตุ้นให้เกิดงานวิจัยทั้งด้าน ANN และ AI มากขึ้น \n",
    "\n",
    "ปีต่อมาหลังจากโครงการนี้ John Von Neumann แนะนำการเลียนแบบฟังก์ชันของเซลล์ประสาทอย่าง่านโดยใช้อุปกรณ์รีเลย์โทรเลขและหลอดสูญญากาศ ในขณะที่นักชีววิทยา\n",
    "ด้านเซลล์ประสาทชื่อ Frank Rosenblatt ณ มหาวิทยาลัยคอร์เนลเริ่มต้นงานเกี่ยวกับเพอร์เซปตรอน (Perceptron) โดยได้ความสนใจจากการทำงานของตาของแมลงวัน \n",
    "ซึ่งเป็นตัวหลักในการประมวลผลให้บินหนีจากภัยอันตราย เพอร์เซปตรอนได้มาจากผลการวิจัยนี้และได้ถูกสร้างบนฮาร์ดแวร์ จัดว่าเป็น ANN เก่าแก่ที่สุดที่ยังมีการใช้งานในปัจจุบัน\n",
    "อยางไรก็ตาม เพอร์เซปตรอนในช่วงเวลานี้นเป็นแบบชั้นเดียวและมีข้อจำกัด โดยในปี 1969 Masrvin Minsky และ Seymour Papert ได้เขียนหนังสือ Perceptrons เพื่อ\n",
    "พิสูจน์ข้อจำกัดนั้น\n",
    "\n",
    "ในปี ค.ศ. 1959 ฺBernard Widrow และ Marcian Hoff แห่งมหาวิทยาลัยสแตนฟอร์ดได้พัฒนาโมเดลมีชื่อเรียกว่า ADALINE และ MADALINE (Multiple ADAptive\n",
    "LINear Elements) ซึ่งเป็น ANN ตัวแรกที่นำมาประยุกต์ใช้กับงานจริง โดยใช้เป็นตัวกรองแบบปรับตัวที่สามารถขจัดเสียงสะท้อนในสายโทรศัพท์ และยังมีการใช้งานเชิง\n",
    "พานิชย์ในปัจจุบัน\n",
    "\n",
    "ความสำเร็จในช่วงต้นนี้ทำให้มีการอวดอ้างศักยภาพของ ANN เดินความเป็นจริงโดยเฉพาะในยุคที่อิเล็กทรอนิกส์ยังไม่พัฒนามาก สร้างความผิดหวังเมื่อ ANN ไม่สามารถทำงาน\n",
    "ได้ตามเป้าหมายและสร้างผลร้ายกับงานวิจัย ทำให้การให้ทุนหยุดชะงักไปช่วงเวลาหนึ่งจนถึงปี 1981 จนกระทั่งในปี 1982 John Hopfield สังกัด ม. Caltech นำเสนอ\n",
    "บทความไปยัง National Academy of Sciences โดยแนวทางของเขาไม่เพียงแต่โมเดลสมองมนุษย์ แต่ะยังสร้างอุปกรณ์ที่มีประโยชน์ โดยแสดงการวิเคราะห์ทางคณิตศาสตร์\n",
    "อย่างชัดเจนว่าโครงข่ายทำงานอย่างไรและทำงานอะไรได้บ้าง อย่างไรก็ตามความสำเร็จของ Hopfiled ส่วนใหญ่มาจากความสามารถในการพูดเพื่อโน้มน้าวผู้ฟัง ขณะที่นวัตกรรม\n",
    "ของเขายังไม่ใช่จุดเด่น ในขณะเดียวกันในงานประชุมที่ประเทศญี่ปุ่นที่แสดงความก้าวหน้าของประเทศคู่แข่งทำให้สหรัฐอเมริกากลัวว่าจะตามไม่ทัน จึงเกิดการกระตุ้นของทุนวิจัย\n",
    "ทางด้านนี้อีกครั้งหนึ่ง\n",
    "\n",
    "ปี ค.ศ. 1989 American INstitute of Physics ได้จัดงานซึ่งกลายเป็นการประชุมประจำปีชื่อว่า Neural Networks for Computing และในปี 1987 Institute \n",
    "of Electrial and Electronic Engineer (IEEE) จัดงาน International Conference on Neural Networks ซึ่งมีผูร่วมงานกว่า 1,800 คน ในปีเดียวกันนี้\n",
    "ความสำเร็จในการประยุกต์ใช้ ANN ในเชิงปฏิบัติเกิดขึ้นที่ห้องปฏิบัติการเบลล์ เมื่อ Yann LeCun ผสมผสานแนวคิดของการสังวัตนาการกับการแพร่กระจายย้อนหลังเพื่อสร้างโครงข่าย \n",
    "LeNet สำหรับจำแนกตัวเลขที่เขียนด้วยลายมือ ซึ่งกรมไปรษณีย์ของสหรัฐอเมริกาได้นำไปใช้งานในช่วงทศวรรษที่ 1990 ในการอ่านรหัสไปรษณีย์บนซองจดหมาย \n",
    "\n",
    "หลังจากนั้นความสนใจด้าน ANN กลับซบเซาลงอีกครั้งเมื่อมีการนำเสนอวิธีการอื่นในการเรียนรู้ของเครื่อง เช่น Support Vector Meahine (SVM) ที่พัฒนาโดย \n",
    "Vladimir Vapnik และ Corinna Cortes จากห้องปฏิบัติการเบลล์ในช่วงต้นทศวรรษ 1990 โดยในช่วงนั้น SVM มีสมรรถนะเยี่ยมยอดสำหรับปัญหาการจำแนกพื้นฐาน \n",
    "เป็นหนึ่งในวิธีการเรียนรู้ของเครื่องจำนวนไม่มากนักที่รองรับโดยทฤษฏีและการวิเคราะห์ทางคณิตศาสตร์อย่างครอบคลุม ทำให้สามารถเข้าใจได้เป็นอย่างดี อย่างไรก็ตาม SVM \n",
    "เริ่มไม่ได้ผลดีสำหรับข้อมูลที่มีขนาดใหญ่เช่นการจำแนกภาพจำนวนมาก ในการใช้ SVM สำหรับปัญหาการรับรู้ดังกล่าวจำเป็นต้องมีการจัดการกับข้อมูลด้วยมือเรียกว่า \n",
    "วิศวกรรมลักษณะเด่น (feature engineering) ซึ่งเป็นกรรมวิธีที่ยากและเปราะบาง \n",
    "\n",
    "ในขณะที่สังคมด้านวิทยาศาสตร์เบนความสนใจจาก ANN ไป ในช่วงทศวรรษ 2010 ได้มีกลุ่มที่ยังคงเกาะติดอยู่กับงานด้านนี้และค้นพบความก้าวหน้าที่สำคัญ ประกอบด้วย \n",
    "Geoffrey Hinton (University of Toronto) Yoshua Bengio (University of Montreal) Yann LeCun (New York University) และ IDSIA \n",
    "(Switzerland) ในปี ค.ศ. 2011 Dan Ciresan จาก IDSIA ชนะการแข่งขันการจำแนกภาพโดยใช้โครงข่ายประสาทเทียมเชิงลึกที่ฝึกหัดโดยใช้ Graphics Processing\n",
    "Unit (GPU) นับเป็นครั้งแรกของความสำเร็จสำหรับการเรียนรู้เชิงลึกสมัยใหม่ ความสำเร็จครั้งใหญ่ตามมาในปี 2012 เมื่อกลุ่มของ Hinton เข้าแข่งขันการจำแนกภาพที่เรียกว่า \n",
    "ILSVRC (ImageNet Large Scale Visual Recognition Challenge) ซึ่งเป็นปัญหาที่ยากมากในขณะนั้น โจทย์คือการจำแนกภาพสีความละเอียดสูงออกเป็น 1000 \n",
    "ประเภทที่แตกต่างกัน หลังจากการฝึกโดยภาพจำนวน 1.4 ล้านภาพ ซึ่งในปีก่อนหน้านั้น ความแม่นยำของผู้ชนะโดยวิธีการอื่นด้านการรับรู้ภาพโดยคอมพิวเตอร์อยู่ที่ 74.3 % \n",
    "แต่ในปี 2012 ทีมแข่งขันที่นำโดย Alex Krizhevsky โดยมี Geoffrey Hinton เป็นที่ปรึกษาสามารถทำความแม่นยำได้ถึง 83.6% หลังจากปีนั้นการแข่งขันนี้ผู้แข่งที่ใช้\n",
    "โครงข่ายประสาทเทียมเชิงลึกชนะมาโดยตลอด ในปี 2015 ผู้ชนะได้ความแม่นยำถึง 96.4% และทำให้การจำแนกภาพ ImageNet ถูกจัดว่าเป็นปัญหาที่สามารถหาคำตอบได้โดยสมบูรณ์ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 โครงข่ายประสาทเทียมเชิงลึก\n",
    "\n",
    "มักมีความเข้าใจผิดกับคำว่า \"เชิงลึก\" ในการเรียนรู้เชิงลึก ซึ่งมิได้มีความหมายในเชิงปรัชญา หรือแปลว่าการเรียนรู้อย่างถ่องแท้แต่อย่างใด แต่เป็นคำคุณศัพท์ที่ขยายความ\n",
    "เกี่ยวกับจำนวนชั้นของโครงข่ายประสาทเทียม โดย ANN ที่มีเฉพาะชั้นที่เป็นอินพุตและเอาต์พุตเรียกว่าเป็นแบบตื้น (shallow) ส่วนโครงข่ายประสาทเทียมเชิงลึก \n",
    "(deep neural network) ซึ่งต่อไปจะเรียกโดยย่อว่า DNN นอกจากชั้นอินพุตและเอาต์พุตแล้วยังประกอบด้วยชั้นแฝง (hidden layer) อย่างน้อยหนึ่งชั้น ตัวอย่างดังใน\n",
    "รูปที่ 1.3\n",
    "\n",
    "<p />  \n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?id=1btDYqvB3KU3AZdsdwT7OPHVjAQxT9qBB\" width=500 />\n",
    "</p>\n",
    "<div align=\"center\">รูปที่ 1.3 ตัวอย่างโครงข่ายประสาทเทียมเชิงลึก (DNN) </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow 2.3.1)",
   "language": "python",
   "name": "tf231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
