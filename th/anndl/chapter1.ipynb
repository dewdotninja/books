{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# บทที่ 1. บทนำ\n",
    "\n",
    "ก่อนจะเข้าสู่เนื้อหาหลัก เราลองหาคำจำกัดความของการเรียนรู้เชิงลึก (deep learning) เริ่มต้นจากโดเมนใหญ่สุด \n",
    "จากคำบรรยายในวิกิพิเดีย ปัญญาประดิษฐ์ (artificial intelligence) \n",
    "หรือที่นิยมเรียกโดยย่อว่า AI คือเชาว์ปัญญาที่แสดงให้เห็นในเครื่องจักรกล \n",
    "แตกต่างจากปัญญาธรรมชาติจากสมองของมนุษย์หรือสัตว์ ดังนั้น AI จะครอบคลุมนวัตกรรมทั้งหมดที่ทำให้คอมพิวเตอร์มีความชาญฉลาดเข้าสู่ปัญญาของมนุษย์ \n",
    "ซึ่งมีขอบเขตที่กว้างมาก การเรียนรู้ของเครื่อง (machine learning) คือเซตย่อยของเอไอที่เน้นการศึกษาขั้นตอนวิธีทางคอมพิวเตอร์ในการเรียนรู้และปรับตัวจากข้อมูล ซึ่งสามารถทำได้\n",
    "หลายแนวทางเช่นการหาค่าเหมาะที่สุด ทฤษฏีกราฟ แต่ในหนังสือนี้จะศึกษาวิธีการใช้โครงข่ายประสาทเทียม (artificial neural network) ซึ่งต่อไปจะอ้างถึงโดยตัวย่อ \n",
    "ANN ในการเรียนรู้ กล่าวได้ว่า ANN คือระบบคอมพิวเตอร์หรือโมเดลทางคณิตศาสตร์ที่ใช้ในการจำลองสมองทางชีวภาพ โดยอาศัยการเรียนรู้หรือเรียกว่าการฝึก (training) \n",
    "โดยข้อมูลตัวอย่าง เมื่อเขียนภาพรวมความสัมพันธ์ของขอบเขตปัญหาที่กล่าวมาจะได้ดังแสดงในรูปที่ 1.1 \n",
    "\n",
    "<p />  \n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?id=1r_T5zq9MMcGXptpF_k1BU5nfC4Kq6WM_\" width=500 />\n",
    "</p>\n",
    "<div align=\"center\">รูปที่ 1.1 ความสัมพันธ์ของปัญญาประดิษฐ์ การเรียนรู้ของเครื่อง และการเรียนรู้เชิงลึก</div>\n",
    "\n",
    "ความแตกต่างสำคัญระหว่างแนวทางการเรียนรู้ของเครื่องกับการโปรแกรมคอมพิวเตอร์ทั่วไปแสดงได้ในรูปที่ 1.2 แผนภาพด้านบนคือการเขียนโปรแกรมในรูปแบบที่เราคุ้นเคย \n",
    "สมมุติว่าต้องการเขียนฟังก์ชันอย่างง่ายเพื่อบวกเลขสองจำนวน คำสั่งในโปรแกรมคือการดำเนินการบวก และอาจมีการตรวจสอบว่าตัวแปรที่ได้รับเป็นประเภทตัวเลข การดำเนินการและเงื่อนไขเหล่านี้คือกฏของฟังก์ชัน และตัวเลขที่เป็นอาร์กิวเมนต์ของฟังก์ชันคือข้อมูล สิ่งที่คืนค่าจากฟังก์ชันหรือเอาต์พุตก็คือผลลัพธ์ของการบวก\n",
    "ซึ่งจะได้คำตอบเป็นตัวเลข ซึ่งสำหรับฟังก์ชันง่ายๆ นี้อาจมองไม่เห็นปัญหา แต่ลองคิดดูเล่นๆ ว่าถ้าต้องการขยายฟังก์ชันนี้ให้รับอินพุตรูปแบบอื่น เช่นถ้าอินพุตเป็นตัวแปรสตริง\n",
    "ให้ต่อข้อความเข้าด้วยกัน หรืออาจเป็นวัตถุอื่นเช่นมะละกอฝานรวมกับมะเขือเทศเป็นส่วนหนึ่งของส้มตำ กฏของโปรแกรมจะต้องถูกเพิ่มเงื่อนไขมากขึ้นจนในที่สุดมีความซับซ้อนเกินกว่าจะจัดการได้\n",
    "หรืออาจเกิดปัญหา\n",
    "ความขัดแย้งกันระหว่างกฎ พิจารณาอีกตัวอย่างหนึ่งที่เกี่ยวข้องกับ AI มากขึ้น เราต้องการสร้างอุปกรณ์ที่ช่วยผู้พิการในกิจกรรมต่างๆ ในชีวิตประจำวัน ตั้งกฏหนึ่งไว้เพื่อความปลอดภัยว่าของมีคม\n",
    "จะต้องอยู่ไม่ใกล้อวัยวะของผู้ใช้เกินค่าที่กำหนด ผลคืออุปกรณ์นี้ไม่สามารถโกนหนวดให้กับเขาได้เพราะวิเคราะห์ว่าเป็นอันตราย คามขัดแย้งของกฏในลักษณะนี้ทำให้แนวทางปัญญาประดิษฐ์ที่ใช้ระบบ\n",
    "ผู้เชี่ยวชาญ (expert systems) ไม่ประสบความสำเร็จเท่าที่ควรและส่งผลให้การวิจัยในด้านนี้หยุดชะงักไปช่วงเวลาหนึ่ง เรียกกันว่าเป็นช่วงฤดูหนาวของ AI\n",
    "\n",
    "<p />  \n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?id=1xmiNtJjHI7XFxTAI92gqJgbbstC4iDzj\" width=500 />\n",
    "</p>\n",
    "<div align=\"center\">รูปที่ 1.2 ความแตกต่างระหว่างการโปรแกรมทั่วไปกับการเรียนรู้ของเครื่อง</div>\n",
    "\n",
    "เมื่อพิจารณากระบวนทัศน์ของการแก้ปัญหาในแนวทางการเรียนรู้ของเครื่องในแผนภาพด้านล่างของรูปที่ 1.2 จะเห็นว่าอินพุตของระบบคือ\n",
    "ข้อมูลและคำตอบ ซึ่งโดยทั่วไปจะมีจำนวนมากและมีความหลากหลาย คอมพิวเตอร์ใช้อินพุตนี้ในการฝึกฝนตัวเองจนกระทั่งได้กฎที่สอดคล้อง\n",
    "กับความต้องการของผู้ใช้มากที่สุด ตัวอย่างที่มีการใช้งานมากสุดคือการจำแนกภาพ เช่นต้องการจำแนกภาพสัตว์เลี้ยงระหว่างสุนัขกับแมว ข้อมูล\n",
    "สำหรับฝึกคือภาพของสุนัขและแมวในอริยาบทต่างๆ จำนวนมากเพียงพอ และคำตอบของภาพนั้นที่เรียกว่า เลเบล (label) หรือความจริงมูลเหตุ \n",
    "(ground truth) หากการฝึกประสบผลสำเร็จ โมเดลที่ได้จะสามารถจำแนกภาพที่เป็นข้อมูลทดสอบ หรือภาพจากกลัองที่ไม่เคยใช้ในการฝึก \n",
    "โดยมีความแม่นยำขึ้นกับหลายปัจจัยเช่น จำนวนข้อมูลในการฝึก สถาปัตยกรรมของโมเดล ความยากง่ายของภาพที่ต้องการพยากรณ์ การเรียนรู้เชิงลึกโดยใช้ ANN \n",
    "เป็นวิธีการหนึ่งที่ใช้ในปัญหาการจำแนกได้อย่างมีประสิทธิภาพ โดยผลจากการแข่งขันมีความแม่นยำเหนือกว่าแนวทางอื่น ทำให้ AI กลับมาได้รับ\n",
    "ความสนใจอีกครั้งจนถึงปัจจุบัน\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 ประวัติโดยย่อของโครงข่ายประสาทเทียม\n",
    "\n",
    "แท้จริงแล้วการจำลองสมองทางชีวภาพโดย ANN มิใช่เป็นวิธีการใหม่ แต่ได้เริ่มต้นมาตั้งแต่ ค.ศ 1943 โดยนักประสาทวิทยา \n",
    "Warren McCulloch และนักคณิตศาสตร์ Waler Pitts เขียนบทความเกี่ยวกับการทำงานของเซลล์ประสาทที่สามารถสร้างโมเดลจำลองเป็นวงจรไฟฟ้า ต่อมาในปี ค.ศ. \n",
    "1949 Donald Hebb ได้เขียนหนังสือชื่อเรื่อง The Organization of Behavior เสริมแนวคิดการทำงานของเซลล์ประสาท ต่อมาในยุคเริ่มต้นของคอมพิวเตอร์ช่วงทศวรรษ\n",
    "ที่ 1950 เริ่มมีการโมเดลทฤษฎีเหล่านี้และจำลองโครงข่ายประาทเทียมครั้งแรกโดย Nathanial Rochester ณ ห้องปฏิบัติการวิจัยของไอบีเอ็ม ซึ่งไม่ประสบผลสำเร็จ ใน\n",
    "ช่วงเวลาดังกล่าวความสนใจในการโปรแกรมคอมพิวเตอร์เป็นไปในแนวทางดั้งเดิมมีมากกว่า แม้ในปี ค.ศ. 1956 จะเกิดโครงการ Darthmouth Summer Research \n",
    "Project on Artificial Intelligence ที่ช่วยกระตุ้นให้เกิดงานวิจัยทั้งด้าน ANN และ AI มากขึ้น \n",
    "\n",
    "ปีต่อมาหลังจากโครงการนี้ John Von Neumann แนะนำการเลียนแบบฟังก์ชันของเซลล์ประสาทอย่าง่านโดยใช้อุปกรณ์รีเลย์โทรเลขและหลอดสูญญากาศ ในขณะที่นักชีววิทยา\n",
    "ด้านเซลล์ประสาทชื่อ Frank Rosenblatt ณ มหาวิทยาลัยคอร์เนลเริ่มต้นงานเกี่ยวกับเพอร์เซปตรอน (Perceptron) โดยได้ความสนใจจากการทำงานของตาของแมลงวัน \n",
    "ซึ่งเป็นตัวหลักในการประมวลผลให้บินหนีจากภัยอันตราย เพอร์เซปตรอนได้มาจากผลการวิจัยนี้และได้ถูกสร้างบนฮาร์ดแวร์ จัดว่าเป็น ANN เก่าแก่ที่สุดที่ยังมีการใช้งานในปัจจุบัน\n",
    "อยางไรก็ตาม เพอร์เซปตรอนในช่วงเวลานี้นเป็นแบบชั้นเดียวและมีข้อจำกัด โดยในปี 1969 Masrvin Minsky และ Seymour Papert ได้เขียนหนังสือ Perceptrons เพื่อ\n",
    "พิสูจน์ข้อจำกัดนั้น\n",
    "\n",
    "ในปี ค.ศ. 1959 ฺBernard Widrow และ Marcian Hoff แห่งมหาวิทยาลัยสแตนฟอร์ดได้พัฒนาโมเดลมีชื่อเรียกว่า ADALINE และ MADALINE (Multiple ADAptive\n",
    "LINear Elements) ซึ่งเป็น ANN ตัวแรกที่นำมาประยุกต์ใช้กับงานจริง โดยใช้เป็นตัวกรองแบบปรับตัวที่สามารถขจัดเสียงสะท้อนในสายโทรศัพท์ และยังมีการใช้งานเชิง\n",
    "พานิชย์ในปัจจุบัน\n",
    "\n",
    "ความสำเร็จในช่วงต้นนี้ทำให้มีการอวดอ้างศักยภาพของ ANN เดินความเป็นจริงโดยเฉพาะในยุคที่อิเล็กทรอนิกส์ยังไม่พัฒนามาก สร้างความผิดหวังเมื่อ ANN ไม่สามารถทำงาน\n",
    "ได้ตามเป้าหมายและสร้างผลร้ายกับงานวิจัย ทำให้การให้ทุนหยุดชะงักไปช่วงเวลาหนึ่งจนถึงปี 1981 จนกระทั่งในปี 1982 John Hopfield สังกัด ม. Caltech นำเสนอ\n",
    "บทความไปยัง National Academy of Sciences โดยแนวทางของเขาไม่เพียงแต่โมเดลสมองมนุษย์ แต่ะยังสร้างอุปกรณ์ที่มีประโยชน์ โดยแสดงการวิเคราะห์ทางคณิตศาสตร์\n",
    "อย่างชัดเจนว่าโครงข่ายทำงานอย่างไรและทำงานอะไรได้บ้าง อย่างไรก็ตามความสำเร็จของ Hopfiled ส่วนใหญ่มาจากความสามารถในการพูดเพื่อโน้มน้าวผู้ฟัง ขณะที่นวัตกรรม\n",
    "ของเขายังไม่ใช่จุดเด่น ในขณะเดียวกันในงานประชุมที่ประเทศญี่ปุ่นที่แสดงความก้าวหน้าของประเทศคู่แข่งทำให้สหรัฐอเมริกากลัวว่าจะตามไม่ทัน จึงเกิดการกระตุ้นของทุนวิจัย\n",
    "ทางด้านนี้อีกครั้งหนึ่ง\n",
    "\n",
    "ปี ค.ศ. 1989 American INstitute of Physics ได้จัดงานซึ่งกลายเป็นการประชุมประจำปีชื่อว่า Neural Networks for Computing และในปี 1987 Institute \n",
    "of Electrial and Electronic Engineer (IEEE) จัดงาน International Conference on Neural Networks ซึ่งมีผู้ร่วมงานกว่า 1,800 คน ในปีเดียวกันนี้\n",
    "ความสำเร็จในการประยุกต์ใช้ ANN ในเชิงปฏิบัติเกิดขึ้นที่ห้องปฏิบัติการเบลล์ เมื่อ Yann LeCun ผสมผสานแนวคิดของการสังวัตนาการกับการแพร่กระจายย้อนหลังเพื่อสร้างโครงข่าย \n",
    "LeNet สำหรับจำแนกตัวเลขที่เขียนด้วยลายมือ ซึ่งกรมไปรษณีย์ของสหรัฐอเมริกาได้นำไปใช้งานในช่วงทศวรรษที่ 1990 ในการอ่านรหัสไปรษณีย์บนซองจดหมาย \n",
    "\n",
    "หลังจากนั้นความสนใจด้าน ANN กลับซบเซาลงอีกครั้งเมื่อมีการนำเสนอวิธีการอื่นในการเรียนรู้ของเครื่อง เช่น Support Vector Meahine (SVM) ที่พัฒนาโดย \n",
    "Vladimir Vapnik และ Corinna Cortes จากห้องปฏิบัติการเบลล์ในช่วงต้นทศวรรษ 1990 โดยในช่วงนั้น SVM มีสมรรถนะเยี่ยมยอดสำหรับปัญหาการจำแนกพื้นฐาน \n",
    "เป็นหนึ่งในวิธีการเรียนรู้ของเครื่องจำนวนไม่มากนักที่รองรับโดยทฤษฏีและการวิเคราะห์ทางคณิตศาสตร์อย่างครอบคลุม ทำให้สามารถเข้าใจได้เป็นอย่างดี อย่างไรก็ตาม SVM \n",
    "เริ่มไม่ได้ผลดีสำหรับข้อมูลที่มีขนาดใหญ่เช่นการจำแนกภาพจำนวนมาก ในการใช้ SVM สำหรับปัญหาการรับรู้ดังกล่าวจำเป็นต้องมีการจัดการกับข้อมูลด้วยมือเรียกว่า \n",
    "วิศวกรรมลักษณะเด่น (feature engineering) ซึ่งเป็นกรรมวิธีที่ยากและเปราะบาง \n",
    "\n",
    "ในขณะที่สังคมด้านวิทยาศาสตร์เบนความสนใจจาก ANN ไป ในช่วงทศวรรษ 2010 ได้มีกลุ่มที่ยังคงเกาะติดอยู่กับงานด้านนี้และค้นพบความก้าวหน้าที่สำคัญ ประกอบด้วย \n",
    "Geoffrey Hinton (University of Toronto) Yoshua Bengio (University of Montreal) Yann LeCun (New York University) และ IDSIA \n",
    "(Switzerland) ในปี ค.ศ. 2011 Dan Ciresan จาก IDSIA ชนะการแข่งขันการจำแนกภาพโดยใช้โครงข่ายประสาทเทียมเชิงลึกที่ฝึกหัดโดยใช้ Graphics Processing\n",
    "Unit (GPU) นับเป็นครั้งแรกของความสำเร็จสำหรับการเรียนรู้เชิงลึกสมัยใหม่ ความสำเร็จครั้งใหญ่ตามมาในปี 2012 เมื่อกลุ่มของ Hinton เข้าแข่งขันการจำแนกภาพที่เรียกว่า \n",
    "ILSVRC (ImageNet Large Scale Visual Recognition Challenge) ซึ่งเป็นปัญหาที่ยากมากในขณะนั้น โจทย์คือการจำแนกภาพสีความละเอียดสูงออกเป็น 1000 \n",
    "ประเภทที่แตกต่างกัน หลังจากการฝึกโดยภาพจำนวน 1.4 ล้านภาพ ซึ่งในปีก่อนหน้านั้น ความแม่นยำของผู้ชนะโดยวิธีการอื่นด้านการรับรู้ภาพโดยคอมพิวเตอร์อยู่ที่ 74.3 % \n",
    "แต่ในปี 2012 ทีมแข่งขันที่นำโดย Alex Krizhevsky โดยมี Geoffrey Hinton เป็นที่ปรึกษาสามารถทำความแม่นยำได้ถึง 83.6% หลังจากปีนั้นการแข่งขันนี้ผู้แข่งที่ใช้\n",
    "โครงข่ายประสาทเทียมเชิงลึกชนะมาโดยตลอด ในปี 2015 ผู้ชนะได้ความแม่นยำถึง 96.4% และทำให้การจำแนกภาพ ImageNet ถูกจัดว่าเป็นปัญหาที่สามารถหาคำตอบได้โดยสมบูรณ์ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 โครงข่ายประสาทเทียมเชิงลึก\n",
    "\n",
    "มักมีความเข้าใจผิดกับคำว่า \"เชิงลึก\" ในการเรียนรู้เชิงลึก ซึ่งมิได้มีความหมายในเชิงปรัชญา หรือแปลว่าการเรียนรู้อย่างถ่องแท้แต่อย่างใด แต่เป็นคำคุณศัพท์ที่ขยายความ\n",
    "เกี่ยวกับจำนวนชั้นของโครงข่ายประสาทเทียม โดย ANN ที่มีเฉพาะชั้นที่เป็นอินพุตและเอาต์พุตเรียกว่าเป็นแบบตื้น (shallow) ส่วนโครงข่ายประสาทเทียมเชิงลึก \n",
    "(deep neural network) ซึ่งต่อไปจะเรียกโดยย่อว่า DNN นอกจากชั้นอินพุตและเอาต์พุตแล้วยังประกอบด้วยชั้นแฝง (hidden layer) อย่างน้อยหนึ่งชั้น ตัวอย่างดังใน\n",
    "รูปที่ 1.3\n",
    "\n",
    "<p />  \n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?id=1btDYqvB3KU3AZdsdwT7OPHVjAQxT9qBB\" width=500 />\n",
    "</p>\n",
    "<div align=\"center\">รูปที่ 1.3 ตัวอย่างโครงข่ายประสาทเทียมเชิงลึก (DNN) </div>\n",
    "\n",
    "**หมายเหตุ :** ในบางแหล่งข้อมูลใช้ตัวย่อ DNN แทนโครงข่ายประสาทหนาแน่น (dense neural network) \n",
    "ซึ่งหมายความว่าเซลล์ทั้งหมดในแต่ละชั้นมีการเชื่อมต่อถึงกัน ในด้านการใช้งานทางปฏิบัติไม่มีความแตกต่างกัน \n",
    "\n",
    "นอกจากการเพิ่มชั้นแฝงในโมเดลแล้ว องค์ประกอบสำคัญอีกประการหนึ่งคือที่เซลล์เอาต์พุตของชั้นก่อนหน้าจะต้องมีฟังก์ชันกระตุ้น \n",
    "(activation function) แบบไม่เป็นเชิงเส้น หากไม่มีส่วนนี้ \n",
    "ชั้นแฝงที่เพิ่มเข้ามาจะไม่มีประโยชน์เพราะสามารถใช้การดำเนินการเชิงเส้นเพื่อยุบรวมกับชั้นก่อนหน้านั้นได้ \n",
    "นอกจากนั้น แต่ละชั้นที่เพิ่มให้กับโครงข่ายอาจมีคุณสมบัติที่แตกต่างกันไป เช่นการใช้ชั้นสังวัตนาการในส่วนหน้า\n",
    "เพื่อเพิ่มสมรรถนะในการเรียนรู้ภาพ หรือชั้นที่ออกแบบเฉพาะสำหรับแปลงข้อความเป็นตัวเลข \n",
    "โมเดลการเรียนรู้เชิงลึกที่ใช้งานจริงอาจประกอบด้วยชั้นจำนวนหลายร้อยชั้น \n",
    "\n",
    "อย่างไรก็ตามถึงแม้ว่าโครงข่ายประสาทเทียมจะมีแนวคิดหรือแรงจูงใจมาจากสมองทางชีวภาพของมนุษย์ \n",
    "ก็ยังไม่มีหลักฐานยืนยันว่าสมองมนุษย์มีกลไกการเรียนรู้ในรูปแบบเดียวกันนี้ ดังนั้นหากจะนิยาม\n",
    "โดยไม่เป็นนิยายทางวิทยาศาสตร์เกินความจริงไป การเรียนรู้เชิงลึกเป็นเพียงกรอบการทำงานเชิงคณิตศาสตร์\n",
    "สำหรับการเรียนรู้จากข้อมูลโดยอาศัยหน่วยประมวลผลที่จัดรูปเป็นชั้นและเชื่อมต่อกันโดยค่าน้ำหนัก \n",
    " ปัญญาของโครงข่ายได้มาจากการปรับค่าน้ำหนักผ่านการฝึก จนกระทั่งทำงานตามต้องการโดยมีความแม่นยำอยู่ในเกณฑ์ที่ยอมรับได้ \n",
    "\n",
    "## 1.3 รูปแบบการเรียนรู้\n",
    "\n",
    "เราสามารถแยกประเภทของการเรียนรู้ได้เป็น 3 รูปแบบดังนี้\n",
    "\n",
    "1. การเรียนรู้แบบมีผู้สอน (supervised learning) เป็นลักษณะการเรียนรู้ที่เข้าใจได้ง่ายสุด \n",
    "เพราะเหมือนกับชีวิตมนุษย์ที่ตั้งแต่เกิดมีพ่อแม่ วัยเรียนมีครูชี้แนะจนถึงอาจารย์สอน พ้นจาก\n",
    "มหาวิทยาลัยก็ยังมีหัวหน้างาน กูเกิลและยูทูบ ดังนั้นในการเรียนรู้แบบนี้จะมีข้อมูลและเป้าหมาย \n",
    "(นิยมเรียกว่าเลเบลหรือความจริงมูลเหตุ) ตัวอย่างเช่นในการฝึกโมเดลเพื่อจำแนกภาพสุนัขและแมว \n",
    "ข้อมูลในการฝึกคือ X = ภาพ และ Y = เลเบลบอกว่าภาพนั้นคือสุนัขหรือแมว หลังจากการฝึกเสร็จสิ้น \n",
    "เราจึงทดสอบโดยการป้อนภาพที่ไม่ได้ใช้ในการฝึก เพื่อให้โมเดลพยากรณ์ว่าเป็นประเภทใด\n",
    "\n",
    "2. การเรียนรู้แบบไม่มีผู้สอน (unsupervised learning) ในการเรียนรู้ประเภทนี้จะไม่มีเลเบลให้ในข้อมูล \n",
    "ดังนั้นโมเดลจะต้องพยายามหาแบบรูปหรือโครงสร้างที่แฝงอยู่ในข้อมูลนั้นเอง ยกตัวอย่างเช่นการจัดกลุ่ม (clustering) \n",
    "โดยการรวมข้อมูลตัวอย่างที่มีลักษณะเด่นคล้ายกันเข้าด้วยกัน หรือการวิเคราะห์องค์ประกอบหลัก \n",
    "(principal component analysis)ที่ขั้นตอนวิธีจะหาทางบีบอัดข้อมูลโดยเลือกเฉพาะลักษณะเด่นที่มีประโยชน์\n",
    "และขจัดส่วนที่เหลือทิ้งโดยอัตโนมัติ\n",
    "\n",
    "3. การเรียนรู้แบบเสริมกำลัง (reinforcement learning) ซึ่งในบางแหล่งข้อมููลเช่นวิกิพิเดียจะจัดเป็นการเรียนรู้แบบไม่มีผู้สอน \n",
    "อย่างไรก็ตามการเรียนรู้แบบเสริมกำลังมีข้อแตกต่างในวิธีการเรียนรู้ โดยโมเดลไม่ได้พยายามหาโครงสร้างที่แฝงในข้อมูล \n",
    "แต่เลือกการกระทำที่จะทำให้ได้รางวัลเป็นผลตอบแทนมากที่สุด โดยอาศัยเครื่องมือทางคณิตศาสตร์เช่นกระบวนการมาร์คอฟ \n",
    "(Markov process) และสมการของเบลแมน (ฺBellman equation)\n",
    "\n",
    "### 1.3.1 แผนภาพการเรียนรู้เชิงลึก\n",
    "\n",
    "จากภาพรวมการทำงานของ DNN จะเห็นว่าขั้นตอนสำคัญคือการเรียนรู้ ซึ่งก็คือการฝึกโมเดลจากข้อมูล รูปที่ 1.4 แสดงแผนภาพการเรียนรู้แบบมีผู้สอนโดย \n",
    "DNN โดยตัวโมเดลประกอบด้วยชั้นของเซลล์ที่เชื่อมต่อกันโดยค่าน้ำหนัก (รวมค่าเอนเอียง) จากข้อมูลอินพุตแต่ะลตัวอย่าง\n",
    "โมเดลจะคำนวณเอาต์พุตและส่งให้กับฟังก์ชันสูญเสียเพื่อเปรียนเทียบกับเลเบลของตัวอย่างนั้นเพื่อคำนวณค่าสูญเสีย \n",
    "ที่เป็นตัววัดความผิดพลาดระหว่างการพยากรณ์กับความจริงมูลเหตุ ค่าสูญเสียนี้จะถูกป้อนให้กับตัวหาค่าเหมาะที่สุดเพื่อปรับค่าน้ำหนักในทิศทางที่ลดค่าสูญเสียให้เหลือน้อยสุด\n",
    "ดังนั้นเมื่อมองในแง่ของขั้นตอนวิธี การฝึกเพื่อเรียนรู้ของ DNN คือการพยากรณ์เอาต์พุตและปรับค่าน้ำหนักแบบวนรอบ \n",
    "จนกระทั่งโมเดลสามารถทำงานได้ตามวัตถุประสงค์โดยมีความแม่นยำอยู่ในเกณฑ์ที่ยอมรับ\n",
    "\n",
    "<p />  \n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?id=1Ahgn-Wgj0_dTOZhCTHwaMR8rJyiqe3Wl\" width=600 />\n",
    "</p>\n",
    "<div align=\"center\">รูปที่ 1.4 แผนภาพการเรียนรู้แบบมีผู้สอนโดย DNN</div>\n",
    "\n",
    "โดยทั่วไปการฝึก DNN ขนาดใหญ่โดยข้อมูลจำนวนมากจะใช้เวลานาน ดัังนั้นนิยมใช้การประมวลผลแบบขนานเข้าช่วย เช่นการใช้ตัวประมวลผลกราฟิก นอกจากนั้น\n",
    "กรรมวิธีการเตรียมข้อมูลเช่นการจัดกลุ่ม (batching) และการปรับค่าไฮเปอร์พารามิเตอร์ต่างๆ สามารถปรับปรุงการฝึกให้ดีขึ้น ซึ่งจะได้กล่าวถึงต่อไปในหนังสือนี้\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 ซอฟต์แวร์สำหรับพัฒนา\n",
    "\n",
    "ถึงแม้ว่าในการพัฒนาการเรียนรู้เชิงลึกสามารถกระทำได้โดยภาษาคอมพิวเตอร์หลายภาษา รวมถึงการใช้โปรแกรมสำเร็จรูปเช่น MATLAB\n",
    "แต่กล่าวได้ว่าภาษาที่ได้รับความนิยมอย่างมากคือไพธอน (Python) เนื่องจากเป็นภาษาเชิงวัตถุระดับสูงที่เริ่มใช้มาตั้งแต่ ค.ศ 1991\n",
    "มีระบบนิเวศน์ที่ค่อนข้างสมบูรณ์ เช่นแพ็กเกจสนับสนุน ชุมชนออนไลน์ที่สามารถขอความช่วยเหลือเมื่อเกิดปัญหา \n",
    "ทางเลือกหนึ่งที่น่าสนใจคือภาษาที่เริ่มต้นไม่นานแต่มีสมรรถนะดีและจุดเด่นหลายประการคือ จูเลีย (Julia) ที่เริ่มมีการใช้งานในมหาวิทยาลัย่ชั้นนำของโลก \n",
    "อย่างไรก็ตาม จูเลียยังเสียเปรียบเรื่องความหลากหลายและสมบูรณ์่ของแพ็กเกจสนับสนุน การเปลี่ยนแปลงของไวยากรณ์คำสั่ง และการช่วยเหลือจากชุมชนยังมีน้อยกว่า \n",
    "\n",
    "ในหนังสือนี้จะเน้นการโปรแกรมภาษาไพธอนโดยใช้แพ็กเกจเทนเซอร์โฟลว์ (TensorFLow) ซึ่งเป็นไลบรารีโอเพนซอร์สด้านการเรียนรู้ของเครื่องและโครงข่ายประสาทเทียมที่ใช้งานง่าย \n",
    "เป็นผลงานการวิจัยและผลิตภัณฑ์ของกูเกิล เดิมถูกพัฒนาโดยทีมกูเกิล เบรน (Google brain) เพื่อใช้ภายในบริษัทกูเกิล แต่ต่อมาเปิดให้สาธารณชนได้ใช้งานภายใต้ \n",
    "Apache License 2.0 เมื่อวันที่ 9 พฤศจิกายน ค.ศ. 2015 (วิกิพิเดีย) เทนเซอร์โฟลว์มีการขยายการรองรับไปยังภาษาอื่นด้วยเช่น ซีพลัสพลัส (C++)\n",
    "จาวาสคริป (JavaScript) รวมถึงจูเลีย \n",
    "\n",
    "**หมายเหตุ :** \n",
    "1. เพื่อความกระชับของเนื้อหา ในหนังสือนี้จะใช้ตัวย่อ TF แทนชื่อไลบรารีเทนเซอร์โฟลว์\n",
    "2. ไลบรารีสำหรับการเรียนรู้เชิงลึกสำหรับไพธอนเดิมรู้จักกันในชื่อ Keras (https://keras.io/) แต่ใน TF เวอร์ชัน 2 ขึ้นไปจะรวม Keras อยู่ในแพ็กเกจแล้ว ไม่จำเป็นต้องติดตั้งเพิ่มเติม\n",
    "    \n",
    "คำว่า \"เทนเซอร์\" คือวัตถุทางคณิตศาสตร์ที่ใช้ในการเก็บข้อมูลหลายมิติ ปกติเราจะคุ้นเคยกับแอเรย์และเมทริกซ์ที่มีสมาชิกเป็นหนึ่งและสองมิติ \n",
    "ข้อมูลที่ใช้สำหรับโมเดลเชิงลึกอาจมีมิติมากกว่านั้น เช่นข้อมูลภาพประกอบด้วยความกว้าง ความสูง จำนวนตัวอย่าง และแชนเนล (channel) ข้อมูล 4 \n",
    "มิตินี้จะถูกจัดเก็บอย่างเหมาะสมโดยเทนเซอร์ที่มีค่าลำดับ่ชั้น (rank) เท่ากับ 4 \n",
    "\n",
    "เราจะแนะนำการใช้งาน TF จากตัวอย่างที่กล่าวได้ว่าเป็นการทักทายโลก (Hello world) ของการเรียนรู้เชิงลึก เริ่มต้นโดยการนำเข้าแพ็กเกจที่ต้องการใช้งาน \n",
    "และตรวจสอบเวอร์ชันของ TF ในหนังสือนี้จะต้องการเวอร์ชันตั้งแต่ 2.0 ขึ้นไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ตัวอย่าง 1.1**\n",
    "\n",
    "สมมุติว่าเราอยากทราบความสัมพันธ์ทางคณิตศาสตร์ระหว่างแอเรย์ของอินพุตและเอาต์พุตชุดหนึ่ง "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-5.0, -3.0, -1.0, 1.0, 3.0, 5.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เนื่องจากเป็นโจทย์ที่ไม่ยาก ผู้อ่านคงสามารถคิดในใจเพื่อหาคำตอบได้ว่า \n",
    "\n",
    "$$\n",
    "y = 2x-3 \\tag {1.1}\n",
    "$$ \n",
    "\n",
    "เป็นความสัมพันธ์ระหว่าง xs และ ys ตามข้อมูลในเซลล์ด้านบน\n",
    "\n",
    "แต่ในปัญหาการเรียนรู้เชิงลึก โมเดลที่สร้างขึ้นจะไม่ทราบสมการคำตอบ แต่อาศัยการเรียนรู้จากชุดข้อมูล xs และ ys \n",
    "และเมื่อผ่านการฝึกแล้วสามารถที่จะพยากรณ์เอาต์พุตที่ถูกต้องหรือใกล้เคียงที่สุดสอดคล้องกับความสัมพันธ์ (1.1) เมื่อป้อนอินพุตเป็นตัวเลขค่าหนึ่ง\n",
    "\n",
    "โจทย์ข้อนี้ต้องการเพียงโมเดลอย่างง่ายที่สุด คือประกอบด้วยหนึ่งอินพุต หนึ่งเอาต์พุต และหนึ่งเซลล์ ใช้คำสั่งสร้างได้ดังนี้ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 09:08:27.792791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 09:08:27.793349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-05 09:08:27.793398: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-05 09:08:27.793431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-05 09:08:27.793464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-06-05 09:08:27.793499: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-06-05 09:08:27.793531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-05 09:08:27.793562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-05 09:08:27.793593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-05 09:08:27.793598: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-05 09:08:27.794343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในขั้นตอนการคอมไพล์ ต้องกำหนดฟังก์ชันสูญเสียและตัวหาค่าเหมาะที่สุด สำหรับปัญหารูปแบบนี้ฟังก์ชันสูญเสียเลือกเป็นแบบค่าผิดพลาดเฉลี่ยกำลังสอง \n",
    "(mean squared error) และตัวหาค่าเหมาะที่สุดแบบลดค่าเกรเดียนต์สโทแคสติก (stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse') #loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในกรรมวิธีการฝึกจะใช้ฟังก์ชัน model.fit() โดยป้อนข้อมูล xs, ys จากเซลล์ด้านบน ทดลองฝึกเป็นจำนวน 500 รอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 10.4139\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3664\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5182\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8273\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2606\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7921\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4013\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0722\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7919\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5506\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3403\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1549\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9894\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8400\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7037\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5781\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4612\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3516\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2481\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1497\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0558\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9656\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8787\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7948\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7135\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6346\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5578\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4831\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4103\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3392\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2698\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2021\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1358\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0710\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0076\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9456\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8849\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8255\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7673\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7104\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6547\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6001\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5466\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4943\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4430\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3928\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3436\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2955\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2483\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2021\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1569\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1126\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0692\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0267\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9851\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9443\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9043\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8652\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8269\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7894\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7526\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7166\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6814\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6468\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6130\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5799\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5474\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5156\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4845\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4540\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4241\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3949\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3662\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3382\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3107\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2838\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2574\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2316\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2063\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1815\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1572\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1335\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1102\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0874\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0650\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0432\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0217\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0007\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9802\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9601\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9403\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9210\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9021\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8836\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8654\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8476\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8302\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8132\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7965\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7801\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7641\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7484\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7330\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7180\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7032\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6888\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6746\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6608\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6472\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6339\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6209\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6081\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5956\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5834\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5714\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5597\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5482\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5369\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5259\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5045\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4942\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4840\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4741\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4548\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4454\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4363\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4273\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4186\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4100\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4015\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3933\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3852\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3773\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3695\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3620\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3545\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3472\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3401\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3331\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3263\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3196\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3130\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3066\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3003\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2941\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2881\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2822\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2764\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2707\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2651\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2597\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2543\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2491\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2440\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2390\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2341\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2293\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2246\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2200\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2154\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2110\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2067\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2024\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1983\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1942\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1902\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1825\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1787\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1751\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1715\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1679\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1645\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1611\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1578\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1546\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1514\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1483\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1452\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1422\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1393\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1365\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1337\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1309\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1282\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1256\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1230\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1205\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1180\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1156\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1132\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1109\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1086\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1064\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1042\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1021\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1000\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0979\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0959\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0939\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0920\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0901\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0883\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0864\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0847\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0829\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0812\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0779\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0763\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0748\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0732\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0717\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0702\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0688\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0674\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0646\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0633\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0620\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0607\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0595\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0583\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0571\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0559\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0548\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0536\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0525\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0514\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0504\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0494\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0483\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0474\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0464\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0454\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0445\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0436\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0427\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0418\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0409\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0401\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0393\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0385\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0377\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0369\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0362\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0354\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0347\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0333\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0326\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0319\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0313\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0306\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0300\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0294\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0288\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0282\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0276\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0270\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0259\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0254\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0249\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0244\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0239\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0234\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0229\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0224\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0220\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0198\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0194\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0190\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0186\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0182\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0131\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0128\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0125\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0120\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0118\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0115\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0113\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0111\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0108\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0106\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0104\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0100\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0098\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0096\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0094\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0092\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0088\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0086\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0081\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0078\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0070\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0067\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0065\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0062\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0061\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0058\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0057\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0054\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0052\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0037\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9724e-04\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7676e-04\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5669e-04\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3705e-04\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1780e-04\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9894e-04\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8047e-04\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6239e-04\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4468e-04\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2733e-04\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1033e-04\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9369e-04\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7738e-04\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6142e-04\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4577e-04\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3046e-04\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1545e-04\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0076e-04\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8637e-04\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7227e-04\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5846e-04\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4494e-04\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3169e-04\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1871e-04\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0600e-04\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9356e-04\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8137e-04\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6942e-04\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5772e-04\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4627e-04\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3504e-04\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2405e-04\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1328e-04\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0274e-04\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9242e-04\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8230e-04\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7240e-04\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6269e-04\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5318e-04\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4387e-04\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3476e-04\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2583e-04\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1708e-04\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0852e-04\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0013e-04\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9191e-04\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8386e-04\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7597e-04\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6825e-04\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6068e-04\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5328e-04\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4602e-04\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3891e-04\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3195e-04\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2513e-04\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1846e-04\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1191e-04\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0550e-04\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9923e-04\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9308e-04\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8706e-04\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8117e-04\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7539e-04\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6973e-04\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6419e-04\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5877e-04\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5345e-04\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4824e-04\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4314e-04\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3815e-04\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3326e-04\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2847e-04\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2378e-04\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1918e-04\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1468e-04\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1027e-04\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0595e-04\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0172e-04\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9758e-04\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9352e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8da83ed940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สังเกตจากค่าสูญเสียที่พิมพ์ออกในแต่ละรอบของการฝึกจะเห็นว่ามีค่าลดลง แสดงว่าโมเดลกำลังเรียนรู้ความสัมพันธ์ระหว่างอินพุต xs และเอาต์พุต ys \n",
    "และปรับปรุงค่าน้ำหนักในทิศทางที่ลดการสูญเสีย หลังจากการฝึก 500 รอบเสร็จสิ้น ต้องการทดสอบโมเดลกับค่าตัวเลขอินพุตใหม่ที่ไม่ได้ใช้ในการฝึก \n",
    "ตัวอย่างเช่น เมื่อป้อนอินพุต $x = 10$ ท่านคิดว่าค่าของเอาต์พุต $y$ ควรเป็นเท่าไร? คิดคำตอบไว้ในใจก่อนรันเซลล์ด้านล่างนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "[[16.959414]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากสมการ (1.1) ค่าที่ถูกต้องควรเป็น 17 แต่ค่าที่พยากรณ์จากโมเดลจะมีความผิดพลาดไปเล็กน้อย โมเดลโครงข่ายประสาทเทียมไม่ทราบสมการที่แท้จริง \n",
    "แต่ทำงานภายใต้หลักการของความน่าจะเป็น ซึ่งในกรณีนี้เราใช้ข้อมูลการฝึกเพียง 6 ตัวอย่างเท่านั้น ท่านอาจทดลองเพิ่มจำนวนตัวอย่างดูว่าได้ความแม่นยำเพิ่มขึ้นหรือไม่\n",
    "\n",
    "ตัวอย่างนี้เป็นเพียงปัญหาของเล่นที่แนะนำการใช้ไลบรารี TF เท่านั้น โมเดลที่ใช้ไม่ได้เป็นแบบเชิงลึกแต่อย่างใด \n",
    "ในการใช้งานทั่วไปโจทย์จะมีความซับซ้อนมากกว่านี้ ซึ่งจำเป็นต้องใช้โมเดลที่มีเซลล์และจำนวนชั้นมากขึ้่น รวมถึงการเลือกใช้ฟังก์ชันสูญเสียและตัวหาค่าเหมาะที่สุดที่สอดคล้องกับปัญหานั้น\n",
    "\n",
    "**ตัวอย่าง 1.2**\n",
    "\n",
    "ในตัวอย่างนี้จะสาธิตการสร้างโครงข่ายประสาทเทียมเชิงสังวัตนาการ (convolutional neural network) หรือเรียกย่อว่า CNN \n",
    "ที่จะได้กล่าวถึงโดยละเอียดในบทที่ 3 โจทย์ปัญหาของตัวอย่างนี้คือการจำแนกภาพตัวเลข 0 - 9 \n",
    "ที่เขียนด้วยลายมือ โดยใช้ชุดข้อมูลจาก MNIST (Modified National Institute of Standards and Technology) ที่สามารถโหลดได้จากคำสั่งเมื่อติดตั้ง TF แล้ว\n",
    "ตัวอย่างนี้นอกจาก TF แล้วจะใช้แพ็กเกจสนับสนุนเพิ่มเติม ใช้คำสั่งเพื่อนำเข้าดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**หมายเหตุ :** สำหรับสองบรรทัดสุดท้ายในเซลล์ด้านบนเป็นคำสั่งนำเข้าเพื่อให้ใช้งานง่ายขึ้น ตัวอย่างเช่นการพิมพ์เพียง Sequential() แทนคำสั่งเต็มรูปแบบ \n",
    "tf.keras.models.Sequential()\n",
    "\n",
    "**สำหรับผู้เขียน :** อ้างอิงบทความนี้ในบรรณานุกรม \n",
    "* Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" \n",
    "Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n",
    "\n",
    "ชุดข้อมูลของ MNIST ประกอบด้วยภาพตัวเลข 0-9 ที่เขียนด้วยลายมือจำนวน 60,000 ภาพ พร้อมเลเบลสำหรับการฝึก และอีก 10,000 ภาพสำหรับชุดทดสอบ \n",
    "เริ่มต้นโดยการโหลดข้อมูล โดยคอมพิวเตอร์ต้องเชื่อมต่ออินเทอร์เน็ต หากเป็นการโหลดครั้งแรกจะเห็นเอาต์พุตจากเซลล์แสดงความก้าวหน้า \n",
    "แต่ถ้าเคยโหลดแล้วจะไม่มีเอาต์พุต เพราะไฟล์ข้อมูลถูกเก็บอยู่อยู่บนคอมพิวเตอร์ของเราแล้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist_data = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ก่อนที่จะใช้ข้อมูลกับโมเดล จะต้องมีการประมวลผลล่วงหน้า โดยปรับมาตราส่วนของพิกเซลให้อยู่ในช่วง 0 - 1 \n",
    "เขียนเป็นฟังก์ชัน scale_data() และเรียกใช้กับข้อมูลใน train_images และ test_images ได้เอาต์พุตอยู่ในเทนเซอร์ \n",
    "scaled_train_images, scaled_test_images ตามลำดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train_images, test_images):\n",
    "    train_images = train_images/255.\n",
    "    test_images = test_images/255.\n",
    "    return train_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_images, scaled_test_images = scale_data(train_images, test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลองตรวจสอบรูปร่างของเทนเซอร์ scaled_train_images พบว่ามีมิติหรือแกน (axis) เท่ากับ 3 คือ จำนวนตัวอย่าง \n",
    "ความกว้างและความสูงของภาพตามลำดับ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในการใช้งานกับ CNN ต้องการแกนที่ 4 เป็นแชนเนล ใช้คำสั่งเพิ่มแกนใหม่ดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_images = scaled_train_images[..., np.newaxis]\n",
    "scaled_test_images = scaled_test_images[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เมื่อจัดรูปข้อมูลแล้ว เ่ราพร้อมที่จะสร้างโมเดล CNN สำหรับฝึกการจำแนกข้อมูล ในตัวอย่างนี้จะใช้โมเดล 6 \n",
    "ชั้นที่มีโครงสร้างและข้อกำหนดดังนี้\n",
    "* ใช้อาร์กิวเมนต์ input_shape เพื่อกำหนดขนาดของอินพุตที่ป้อนให้กับชั้นแรก\n",
    "* ชั้นที่สองเป็นแบบเชิงสังวัตนาการที่มีเคอร์เนลขนาด 3 x 3 และตัวกรอง 8 ตัว ใช้การเสริมเต็ม (padding) แบบ 'SAME' \n",
    "(คือการเพิ่มค่าศูนย์เพื่อให้ขนาดความกว้างและความสูงของเอาต์พุตคงเดิม) และฟังก์ชันการกระตุ้นแบบ ReLU \n",
    "* ชั้นที่สามเป็นแบบแมกซ์พูลลิง (max pooling) ขนาดหน้าต่าง 2 x 2 ช่วงก้าว (stride) ใช้ค่าโดยปริยาย\n",
    "* ชั้นแบน (flatten) เพื่อคลี่อินพุตออกเป็นเทนเซอร์มิติเดียว\n",
    "* ชั้นต่อจากนี้ไปเป็น DNN ประกอบด้วยชั้นแฝง 2 ่ชั้น แต่ละชั้นมี 64 เซลล์และฟังก์ชันกระตุ้นแบบ ReLU\n",
    "* ชั้นเอาต์พุตมีเซลล์ 10 หน่วยเพื่อจำแนกตัวเลข 0 - 9 และฟังก์ชันกระตุ้นแบบซอฟต์แมกซ์ (softmax)\n",
    "\n",
    "ทั้งหมดเขียนได้เป็นฟังก์ชัน get_model() ดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(8,(3,3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        MaxPooling2D([2,2]),\n",
    "        Flatten(),\n",
    "        Dense(64,activation='relu'),\n",
    "        Dense(64,activation='relu'),\n",
    "        Dense(10,activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เรียกใช้ฟังก์ชันเพื่อสร้างโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(scaled_train_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ขั้นตอนต่อไปคือการคอมไพล์โมเดลโดยวิธี compile() กำหนดประเภทของตัวหาค่าเหมาะที่สุด ฟังก์ชันสูญเสีย \n",
    "และตัววัดสมรรถนะของโมเดล ในตัวอย่างนี้จะใช้ตัวหาค่าเหมาะที่สุดแบบ 'adam' ฟังก์ชันสูญเสีย \n",
    "'sparse_categorical_crossentropy' และวัดสถานะโดย 'accuracy' คือความแม่นยำในการจำแนก "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในการฝึกโมเดลโดยใช้ชุดข้อมูล MNIST จะใช้วิธี fit() ของวัตถุ model ตั้งค่ารอบการฝึกเท่ากับ 10 และคืนค่าประวัติการฝึก \n",
    "เพื่อใช้ในการพล็อตกราฟการเรียนรู้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 3s 10ms/step - loss: 0.4457 - accuracy: 0.8785\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1332 - accuracy: 0.9613\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0872 - accuracy: 0.9743\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0680 - accuracy: 0.9801\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0566 - accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0486 - accuracy: 0.9850\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0416 - accuracy: 0.9877\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0356 - accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0326 - accuracy: 0.9904\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0275 - accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(scaled_train_images, train_labels,epochs=10,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากเอาต์พุตที่แสดงในแต่ละรอบการฝึก จะพบว่าค่าสูญเสียมีค่าน้อยลง ขณะที่ความแม่นยำสูงขึ้น หลังจากการฝึก 10 \n",
    "รอบได้ค่าสูญเสียประมาณ 0.03 และความแม่นยำประมาณ 99% ผู้อ่านอาจได้เอาต์พุตที่แตกต่างกันบ้างเล็กน้อยในการรันแต่ละครั้ง\n",
    "\n",
    "ต้องการพล็อตกราฟของความแม่นยำและค่าสูญเสียในการฝึกแต่ละรอบ จะใช้แพ็กเกจ panda ช่วย โดยโหลดค่า history \n",
    "ที่ได้จากโมเดลเข้าใน DataFrame และใช้วิธี plot เพื่อแสดงกราฟ ผลที่ได้ดังแสดงในรูปที่ 1.5 และ 1.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Epochs'), Text(0, 0.5, 'Accuracy')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_plot = frame.plot(y=\"accuracy\", title=\"Accuracy vs Epochs\", legend=False)\n",
    "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "รูปที่ 1.5 กราฟความแม่นยำเทียบกับจำนวนรอบของการฝึก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Epochs'), Text(0, 0.5, 'Loss')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plot = frame.plot(y=\"loss\", title = \"Loss vs Epochs\",legend=False)\n",
    "loss_plot.set(xlabel=\"Epochs\", ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "รูปที่ 1.6 กราฟความสูญเสียเทียบกับจำนวนรอบของการฝึก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุดท้ายคือต้องการประเมินสมรรถนะของโมเดลโดยใช้สชุดข้อมูลทดสอบ เริ่มโดยการใช้วิธี model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9826\n",
      "ค่าสูญเสียจากข้อมูลทดสอบ: 0.052959978580474854\n",
      "ความแม่นยำจากข้อมูลทดสอบ: 0.9825999736785889\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(scaled_test_images,test_labels)\n",
    "print(f\"ค่าสูญเสียจากข้อมูลทดสอบ: {test_loss}\")\n",
    "print(f\"ความแม่นยำจากข้อมูลทดสอบ: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จะพบว่าค่าที่ประเมินได้มีค่าสูญเสียมากกว่าและความแม่นยำน้อยกว่าตัวเลขที่ได้จากข้อมูลการฝึกเล็กน้อย \n",
    "ทั้งนี้เนื่องจากเราได้ใช้ภาพทดสอบที่โมเดลไม่เคยเห็นมาก่อน อย่างไรก็ตามค่าเหล่านี้อยู่ในเกณฑ์ที่ยอมรับได้\n",
    "\n",
    "สำหรับการตรวจสอบผลการพยากรณ์ของโมเดล ในรูปที่ 1.6 จะสุ่มเลือก 4 ภาพตัวเลขจากชุดข้อมูลทดสอบ \n",
    "พร้อมแสดงภาพและเลเบลของแต่ละภาพทางด้านซ้าย ส่วนทางด้านขวาคือกราฟแท่งแสดงความน่าจะเป็น โดยกราฟแท่งที่มีค่าสูงสุดคือตัวเลขที่โมเดลพยากรณ์ ทดลองรันเซลด้านล่างนี้ตามจำนวนครั้งที่ต้องการ \n",
    "ตรวจสอบว่ามีภาพใดที่โมเดลทายผิด และลองพิจารณาหาสาเหตุที่ภาพนั้นสร้างความสับสนให้กับโมเดล \n",
    "ตัวอย่างเช่นเลข 0 อาจเขียนไม่ครบวง หรือเลข 7 ที่อาจมีการเขียนคล้ายเลข 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_test_images = scaled_test_images.shape[0]\n",
    "\n",
    "random_inx = np.random.choice(num_test_images, 4)\n",
    "random_test_images = scaled_test_images[random_inx, ...]\n",
    "random_test_labels = test_labels[random_inx, ...]\n",
    "\n",
    "predictions = model.predict(random_test_images)\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 12))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=-0.2)\n",
    "\n",
    "for i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n",
    "    axes[i, 0].imshow(np.squeeze(image))\n",
    "    axes[i, 0].get_xaxis().set_visible(False)\n",
    "    axes[i, 0].get_yaxis().set_visible(False)\n",
    "    axes[i, 0].text(10., -1.5, f'Digit {label}')\n",
    "    axes[i, 1].bar(np.arange(len(prediction)), prediction)\n",
    "    axes[i, 1].set_xticks(np.arange(len(prediction)))\n",
    "    axes[i, 1].set_title(f\"Categorical distribution. Model prediction: {np.argmax(prediction)}\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "รูปที่ 1.6 ผลการพยากรณ์เปรียบเทียบกับเลเบลจริง\n",
    "\n",
    "อีกวิธีการหนึ่งในการสร้างโมเดลบน TF คือใช้ API เชิงฟังก์ชัน ซึ่งในตัวอย่างง่ายนี้จะไม่เห็นข้อได้เปรียบและยุ่งยากขึ้น \n",
    "อย่างไรก็ตามวิธีนี้มีประโยชน์ในกรณีที่ต้องการเข้าถึงเอาต์พุตหรือค่าพารามิเตอร์ในแต่ละชั้นของโมเดลได้อย่างสะดวก \n",
    "หรือการสร้างโมเดลที่มีหลายอินพุตหลายเอาต์พุต หรือมีการสร้างทางลัดระหว่างชั้น (เนื้อหาในบทที่ 4)\n",
    "\n",
    "โมเดลในตัวอย่าง 1.2 สร้างโดยใช้ API เชิงฟังก์ชันได้ดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape=scaled_train_images[0].shape\n",
    "inputs = Input(input_shape)\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D([2,2])(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 การใช้งาน TF เบื้องต้น\n",
    "\n",
    "ในหัวข้อนี้จะอธิบายและสาธิตการใช้งานฟังก์ชันพื้นฐานของไลบรารี TF \n",
    "เพื่อเสริมความเข้าใจก่อนการศึกษาและพัฒนาในบทต่อไปของหนังสือ \n",
    "\n",
    "### 1.5.1 ค่าคงที่ ตัวแปร และเทนเซอร์\n",
    "\n",
    "ในการใช้งานไลบรารี TF นอกเหนือจากการรันตัวอย่างอย่างง่าย มักจะต้องมีการสร้างตัวแปรที่สามารถทำงานร่วมกับโมเดล\n",
    "หรือว่าในโครงสร้างภายในของโมเดลเองก็จะมีการรับอินพุตและส่งผ่านตัวแปรระหว่างชั้นจนถึงการส่งออกเอาต์พุต ตัวแปรของ \n",
    "TF อาจมีลักษณะคล้ายตัวแปรที่สร้างโดยไลบรารี numpy แต่บางครั้งอาจต้องมีการแปลงระหว่างไลบรารีจึงสามารถใช้งานได้ \n",
    "เรามักเรียกตัวแปรใน TF โดยรวมว่าเทนเซอร์ ซึ่งครอบคลุมถึงข้อมูล 3 มิติขึ้นไป\n",
    "\n",
    "ในที่นี้ตั้งสมมุติฐานว่าได้นำเข้าเทนเซอร์โฟลว์โดยตั้งชื่อว่า tf การสร้างเทนเซอร์ค่าคงที่ทำได้โดยคำสั่ง tf.constant() เช่น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1 -2]\n",
      "  [ 0  5]]\n",
      "\n",
      " [[ 3  2]\n",
      "  [ 7 -4]]], shape=(2, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[[1,-2],[0,5]],[[3,2],[7,-4]]])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สมาชิกในเทนเซอร์ที่สร้างโดย tf.constant() จะไม่สามารถเปลี่ยนแปลงค่าได้ การแปลงค่าเป็นตัวแปร numpy \n",
    "ทำได้โดยใช้เมธอด numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1, -2],\n",
       "        [ 0,  5]],\n",
       "\n",
       "       [[ 3,  2],\n",
       "        [ 7, -4]]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สำหรับค่าคงที่ที่มีการใช้งานบ่อย คือมีสมาชิกเท่ากับ 0 หรือ 1 ทั้งหมด ใช้คำสั่ง tf.zeros() หรือ tf.ones() ตามลำดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c0 = tf.zeros(shape=(2,3))\n",
    "print(c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c1 = tf.ones(shape=(3,2))\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หากต้องการเปลี่ยนแปลงค่าในเทนเซอร์ต้องใช้เมธอด tf.Variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2, 2) dtype=int32, numpy=\n",
      "array([[[ 1, -2],\n",
      "        [ 0,  5]],\n",
      "\n",
      "       [[ 3,  2],\n",
      "        [ 7, -4]]], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable([[[1,-2],[0,5]],[[3,2],[7,-4]]])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สามารถใส่อาร์กิวเมนต์เพิ่มเติมได้ เช่นถ้าต้องการกำหนดประเภทของตัวแปรให้ใส่เป็นอาร์กิวเมนต์ dtype \n",
    "หรือกำหนดชื่อโดย name=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'my_variable:0' shape=(2, 2, 2) dtype=float32, numpy=\n",
      "array([[[ 1., -2.],\n",
      "        [ 0.,  5.]],\n",
      "\n",
      "       [[ 3.,  2.],\n",
      "        [ 7., -4.]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable([[[1,-2],[0,5]],[[3,2],[7,-4]]],dtype=tf.float32, name='my_variable')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การเปลี่ยนแปลงค่าตัวแปรภายหลังทำได้โดยเมธอด assign() เช่น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 2, 2) dtype=float32, numpy=\n",
       "array([[[ 1., -2.],\n",
       "        [-3.,  4.]],\n",
       "\n",
       "       [[-5.,  6.],\n",
       "        [ 7., -8.]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign([[[1,-2],[-3,4]],[[-5,6],[7,-8]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การแปลงเป็นตัวแปร numpy ทำได้เช่นเดียวกับค่าคงที่ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., -2.],\n",
       "        [-3.,  4.]],\n",
       "\n",
       "       [[-5.,  6.],\n",
       "        [ 7., -8.]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตัวแปรที่ใช้เป็นอินพุตของโมเดลและส่งผ่านระหว่างชั้นไปยังเอาต์พุตจะเป็นแบบเทนเซอร์ ยกตัวอย่างผังการคำนวณอย่างง่าย \n",
    "คือการบวกตัวแปรเดิมด้วยเทนเซอร์อีกตัวหนึ่ง ผลลัพธ์ที่ได้จะถูกปรับเป็น tf.tensor โดยอัตโนมัติ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[ 2., -2.],\n",
       "        [-3.,  5.]],\n",
       "\n",
       "       [[-5.,  7.],\n",
       "        [ 8., -8.]]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v + [[[1,0],[0,1]],[[0,1],[1,0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เช่นเดียวกับเอาต์พุตของแต่ละชั้นที่สร้างโดยวิธี API เชิงฟังก์ชันจะเป็นเทนเซอร์ประเภท KerasTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 8), dtype=tf.float32, name=None), name='conv2d_2/Relu:0', description=\"created by layer 'conv2d_2'\")\n"
     ]
    }
   ],
   "source": [
    "input_shape=scaled_train_images[0].shape\n",
    "inputs = Input(input_shape)\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same')(inputs)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 การเข้าถึงชั้นของโมเดล\n",
    "\n",
    "ยกตัวอย่างการสร้างโมเดลโดยวิธี API เชิงฟังก์ชัน (สังเกตว่ามีการใช้อาร์กิวเมนต์เพื่อระบุชื่อให้กับแต่ละชั้นด้วย)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "input_shape=scaled_train_images[0].shape\n",
    "inputs = Input(shape=(32,1), name='input_layer')\n",
    "x = Conv1D(3,5, activation='relu',name='conv_layer')(inputs)\n",
    "x = MaxPooling1D(3, name='pooling_layer')(x)\n",
    "x = Flatten(name='flatten_layer')(x)\n",
    "x = Dense(32, activation='relu', name='dense_layer')(x)\n",
    "outputs = Dense(1, activation='sigmoid', name='output_layer')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ใช้คำสั่งเพื่อพิมพ์ข้อมูลของแต่ละชั้นออกเอาต์พุต"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.input_layer.InputLayer object at 0x7f8d23390940>, <keras.layers.convolutional.conv1d.Conv1D object at 0x7f8dac498850>, <keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7f8d20ea27f0>, <keras.layers.reshaping.flatten.Flatten object at 0x7f8dac498670>, <keras.layers.core.dense.Dense object at 0x7f8d20ea2160>, <keras.layers.core.dense.Dense object at 0x7f8d233a3670>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยชั้นจะเรียงลำดับจากตัวชี้ 0 ถึง L-1 โดย L คือจำนวนชั้นทั้งหมด เราสามารถเข้าถึงแต่ละชั้นได้โดยใช้ตัวชี้ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x7f8dac498850>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การเข้าถึงชั้นของโมเดลในลักษณะนี้ทำให้สามารถเจาะลึกข้อมูลของชั้นที่ต้องการตรวจสอบได้ เช่นค่าน้ำหนักและค่าเอนเอียง \n",
    "โดยค่าที่แสดงเป็นค่าที่กำหนดเริ่มต้นเนื่องจากยังไม่ได้ผ่านการฝึก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'conv_layer/kernel:0' shape=(5, 1, 3) dtype=float32, numpy=\n",
      "array([[[ 0.51229477, -0.37336355,  0.1699158 ]],\n",
      "\n",
      "       [[-0.051799  ,  0.4327008 , -0.46329454]],\n",
      "\n",
      "       [[ 0.24984056,  0.05601174,  0.27030498]],\n",
      "\n",
      "       [[-0.12198284,  0.37814146, -0.42012239]],\n",
      "\n",
      "       [[-0.09724349, -0.5134095 ,  0.00542837]]], dtype=float32)>, <tf.Variable 'conv_layer/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1].weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สามารถเปลี่ยนจาก weights เป็น kernel หรือ bias หากต้องการเฉพาะค่าน้ำหนักหรือค่าเอนเอียง \n",
    "หากต้องการค่าน้ำหนักและค่าเอนเอียงในรูปของแอเรย์ numpy ใช้เมธอด get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 0.51229477, -0.37336355,  0.1699158 ]],\n",
      "\n",
      "       [[-0.051799  ,  0.4327008 , -0.46329454]],\n",
      "\n",
      "       [[ 0.24984056,  0.05601174,  0.27030498]],\n",
      "\n",
      "       [[-0.12198284,  0.37814146, -0.42012239]],\n",
      "\n",
      "       [[-0.09724349, -0.5134095 ,  0.00542837]]], dtype=float32), array([0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หากในการสร้างโมเดลมีการตั้งชื่อแต่ละชั้นไว้ วิธีการหนึ่งที่สะดวกในการเข้าถึงแต่ละชั้นของโมเดลคือระบุชื่อ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv_layer/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(model.get_layer('conv_layer').bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 การเข้าถึงเทนเซอร์ในโมเดล\n",
    "\n",
    "สังเกตว่าค่าของพารามิเตอร์ในโมเดลจะเป็นชนิด tf.Variable แตกต่างจากข้อมูลที่ถ่ายทอดจากอินพุตสู่เอาต์พุตในโมเดล \n",
    "จะเป็นชนิดเทนเซอร์ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 1), dtype=tf.float32, name='input_layer'), name='input_layer', description=\"created by layer 'input_layer'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 3), dtype=tf.float32, name=None), name='conv_layer/Relu:0', description=\"created by layer 'conv_layer'\")\n"
     ]
    }
   ],
   "source": [
    "print(model.get_layer('conv_layer').input)\n",
    "print(model.get_layer('conv_layer').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การเข้าถึงข้อมูลเทนเซอร์ที่ไหลในโมเดลมีประโยชน์ในกรณีที่ต้องการสร้างโมเดลใหม่ \n",
    "โดยให้อินพุตเป็นค่าจากเอาต์พุตของบางชั้นในอีกโมเดลหนึ่ง ซึ่งเป็นวิธีการที่สนับสนุนการถ่ายโอนการเรียนรู้ในบทที่ 4 \n",
    "ในบทนี้จะกล่าวถึงในเชิงแนะนำวิธีการเท่านั้น\n",
    "\n",
    "จากโมเดลด้านบน สมมุติว่าต้องการเปลี่ยนจากเอาต์พุตการจำแนกทวิภาคในด้านบนเป็นเอาต์พุตที่สามารถจำแนกได้ 10 ประเภท\n",
    "โดยชั้นที่อยู่เหนือขึ้นไปยังคงเดิม ทำได้โดยเข้าถึงเอาต์พุตของชั้นก่อนหน้าเอาต์พุตดังนี้ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_output = model.get_layer('dense_layer').output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สร้างโมเดลใหม่ชื่อ model2 ประกอบด้วยชั้นทุกชั้นของ model ยกเว้นชั้นเอาต์พุต"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs=model.input, outputs=dense_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หลังจากนั้นสร้าง model3 ประกอบด้วยทุกชั้นของ model2 และเพิ่มชั้นเอาต์พุตใหม่สำหรับการจำแนก 10 ประเภท"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    model2,\n",
    "    Dense(10, activation='softmax', name='new_output_layer')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หรือหากใช้ API เชิงฟังก์ชัน สามารถสร้างได้โดยคำสั่งดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outputs = Dense(10, activation='softmax', name='new_output_layer')(model2.output)\n",
    "model3 = Model(inputs=model2.input, outputs=new_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.4 พื้่นฐานการถ่ายโอนการเรียนรู้\n",
    "\n",
    "การถ่ายโอนการเรียนรู้ (transfer learning) คือวิธีการที่มีการใช้งานอย่างแพร่หลาย ยกตัวอย่างผู้พัฒนาโมเดล CNN \n",
    "ที่มีความลึกมาก และใช้ข้อมูลขนาดใหญ่เพื่อฝึกโมเดลเป็นเวลานานโดยใช้ทรัพยากรของห้องปฏิบัติการที่มีสมรรถนะสูง \n",
    "สมมุติว่าโมเดลที่ผ่านการฝึกเรียกว่าโมเดล A สามารถจำแนกวัตถุบนโลกได้ 1000 ประเภท \n",
    "และผู้พัฒนาได้ยินยอมให้กับบุคคลทั่วไปสามารถดาวน์โหลดโมเดลไปใช้งานได้\n",
    "เราเป็นนักพัฒนาสำหรับโครงงานขนาดเล็กกว่าที่ต้องการจำแนกวัตถุเพียง 10 ประเภท \n",
    "มีข้อมูลสำหรับฝึกไม่มากนักและเครื่องคอมพิวเตอร์ก็มีสมรรถนะไม่สูง แทนที่จะสร้างโมเดลเองและฝึกโดยข้อมูลจำนวนน้อย \n",
    "เราสามารถนำเอาโมเดล A มาใช้งานโดยเปลี่ยนชั้นส่วนเอาต์พุตเป็นการจำแนก 10 ประเภท \n",
    "หรืออาจมีการเปลี่ยนชั้นก่อนหน้าเอาต์พุตจำนวนหนึ่ง และฝึกเฉพาะชั้นส่วนที่เปลี่ยนแปลง \n",
    "โดยไม่ต้องการแตะต้องพารามิเตอร์ส่วนใหญ่ของโมเดล A ซึ่งผ่านการฝึกมาอย่างดีแล้ว\n",
    "ในหัวข้อย่อยนี้จะกล่าวเฉพาะพื้นฐานการดำเนินการเพื่อสนับสนุนการถ่ายโอนการเรียนรู้ \n",
    "คือการปิดกั้นพารามิเตอร์ของโมเดลในส่วนที่ไม่ต้องการฝึก \n",
    "\n",
    "เพื่อความต่อเนื่องในการอธิบายจะคัดลอกโค้ดการสร้างโมเดลในตัวอย่าง 1.2 มาใส่ในเซลล์ด้านล่างนี้เพื่อใช้เป็นตัวอย่าง \n",
    "โดยเพิ่มอาร์กิวเมนต์เป็นชื่อของแต่ละชั้นเพื่อความสะดวกในการเข้าถึง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=scaled_train_images[0].shape\n",
    "inputs = Input(input_shape)\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same', name='conv2d_layer')(inputs)\n",
    "x = MaxPooling2D([2,2], name='maxpool2d_layer')(x)\n",
    "x = Flatten(name='flatten_layer')(x)\n",
    "x = Dense(64, activation='relu', name='dense_layer1')(x)\n",
    "x = Dense(64, activation='relu', name='dense_layer2')(x)\n",
    "outputs = Dense(10, activation='softmax', name='output_layer')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สมมุติว่าต้องการปิดกั้นชั้น conv2d_layer และ dense1_layer ไม่ให้มีการฝึกพารามิเตอร์ ทำได้โดยเพิ่มอาร์กิวเมนต์ \n",
    "trainable=False ให้กับชั้นที่ไม่ต้องการฝึก (สำหรับชั้น maxpool2d_layer และ flatten_layer \n",
    "ไม่มีพารามิเตอร์การเรียนรู้)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(8, (3,3), activation='relu', padding='same', name='conv2d_layer',trainable=False)(inputs)\n",
    "x = MaxPooling2D([2,2], name='maxpool2d_layer')(x)\n",
    "x = Flatten(name='flatten_layer')(x)\n",
    "x = Dense(64, activation='relu', name='dense_layer1',trainable=False)(x)\n",
    "x = Dense(64, activation='relu', name='dense_layer2')(x)\n",
    "outputs = Dense(10, activation='softmax', name='output_layer')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในกรณีที่ต้องการปิดกั้นการเรียนรู้ของบางชั้นหลังจากสร้างโมเดลแล้ว ใช้เมธอด get_layer() \n",
    "เพื่อเข้าถึงชั้นนั้นและตั้งค่า trainable=False ได้ดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('conv2d_layer').trainable=False\n",
    "model.get_layer('dense_layer1').trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เมื่อใช้คำสั่ง model.summary() จะเห็นในส่วนท้ายว่าพารามิเตอร์ 100,416 ตัวจะถูกปิดกั้นการฝึก \n",
    "โดยจะมีค่าเท่ากับจำนวนพารามิเตอร์ของชั้น conv2d_layer และ dense_layer1 รวมกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_layer (Conv2D)       (None, 28, 28, 8)         80        \n",
      "                                                                 \n",
      " maxpool2d_layer (MaxPooling  (None, 14, 14, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_layer (Flatten)     (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_layer1 (Dense)        (None, 64)                100416    \n",
      "                                                                 \n",
      " dense_layer2 (Dense)        (None, 64)                4160      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,306\n",
      "Trainable params: 4,810\n",
      "Non-trainable params: 100,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หลังจากนี้เราสามารถตัดชั้นเอาต์พุตและชั้นก่อนหน้าเอาต์พุตออก และเพิ่มชั้นใหม่ที่มีจำนวนเอาต์พุตการจำแนกตามต้องการ \n",
    "การดำเนินการทิ้งให้เป็นแบบฝึกหัด "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.5 การบันทึกและโหลดโมเดล\n",
    "\n",
    "หลังจากการฝึกโมเดลจนได้ผลเป็นที่น่าพอใจ เราสามารถบันทึกโมเดลลงบนดิสก์\n",
    "รูปแบบมี 2 ประเภทคือของ TF (ค่าโดยปริยาย) หรือรูปแบบ hdf5 (hierarchical data format) เมื่อใส่นามสกุล .h5 \n",
    "สมมุติว่าต้องการบันทึกโมเดลชื่อ model ใช้คำสั่งดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_filename/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_filename/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save('model_filename') # TF format\n",
    "model.save('model_filename.h5') # hdf5 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ไฟล์จะถูกบันทึกในไดเรคทอรีที่ใช้งานอยู่ โดยกรณีรูปแบบของ TF จะสร้างไดเรคทอรีย่อยตามชื่อไฟล์ที่ใส่เป็นอาร์กิวเมนต์และบันทึกข้อมูลเป็นกลุ่มของไฟล์\n",
    "ส่วนรูปแบบ hdf5 จะบันทึกเป็นไฟล์เดี่ยว\n",
    "\n",
    "สำหรับการโหลดโมเดลจะต้องนำเข้าฟังก์ชัน load_model และเรียกใช้โดยใส่อาร์กิวเมนต์เป็นชื่อของโมเดลที่บันทึกไว้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('model_filename')\n",
    "new_model2 = load_model('model_filename.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราสามารถตั้งค่าฟังก์ชันเรียกกลับให้บันทึกโมเดลในขณะฝึกตามเงื่อนไขที่กำหนดได้ด้วย โดยเลือกบันทึกโมเดลทั้งหมดหรือเฉพาะค่าพารามิเตอร์ก็ได้ \n",
    "ศึกษาเพิ่มเติมได้จากเพจอ้างอิงของ TF\n",
    "\n",
    "สำหรับข้อมูลการฝึกที่อยู่ในไฟล์ history สามารถจัดเก็บได้ในรูปแบบไบนารีหรือ json ในที่นี้เราจะแสดงโค้ดสำหรับอย่างหลัง "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('history.json', 'w') as file:\n",
    "    json.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ส่วนการโหลดเข้าสู่ตัวแปรดิกชันนารีใช้โค้ดดังนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.json') as json_file:\n",
    "    saved_history = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สังเกตว่าในการใช้งานดิกชันนารีที่โหลดเข้ามาคือ saved_history จะเหมือนกับ history.history จากการฝึก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 โครงสร้างของหนังสือ\n",
    "\n",
    "เนื้อหาในหนังสือนี้เป็นการศึกษาการเรียนรู้เชิงลึกในการแก้ปัญหาหลายรูปแบบ โดยจำกัดขอบเขตเฉพาะการเรียนรู้แบบมีผู้สอน \n",
    "หลังจากการแนะนำเบื้องต้นในบทนี้แล้ว บทที่ 2 กล่าวถึงพื้นฐานโครงข่ายประสาทเทียมตั้งแต่แบบไม่มีชั้นแฝงที่รู้จักกันในชื่อ \n",
    "โมเดลการถดถอยเชิงเส้นและการถดถอยลอจิสติก ซึ่งทำให้เข้าใจหลักการของผังการไหลด้านหน้าและการแพร่กระจายย้อนกลับ \n",
    "การเรียนรู้ของโมเดลแท้จริงแล้วคือการปรับค่าพารามิเตอร์ในทิศทางที่ทำให้ค่าสูญเสียต่ำสุด ประโยชน์ของฟังก์ชันกระตุ้นแบบไม่เป็นเชิงเส้น\n",
    "หลังจากการปรับปรุงโดยเพิ่มชั้นแฝงทำให้เป็นโมเดลที่มีความลึกเรียกว่า DNN \n",
    "เพื่อความเข้าใจกลไกภายใน ในบทนี้จะกล่าวถึงการเขียนโค้ดภาษาไพธอนโดยไม่ใช้ไลบรารี TF สำหรับ DNN ที่มีความซับซ้อนไม่มาก \n",
    "แต่ในกรณีทั่วไปแนะนำให้ใช้ไลบรารี เมื่อทดสอบโมเดล DNN ในการจำแนกภาพพบว่าได้ความแม่นยำไม่สูงมาก \n",
    "ทั้งนี้เนื่องจาก DNN ไม่มีการใช้ข้อมูลเชิงพื้นที่อันเป็นองค์ประกอบสำคัญของข้อมูลภาพ \n",
    "\n",
    "ในบทที่ 3 กล่าวถึงการปรับปรุงโครงข่ายประสาทเทียมโดยปรับแต่งไฮเปอร์พารามิเตอร์เพื่อให้ได้ประสิทธิภาพที่ดี \n",
    "เริ่มต้นจากการอธิบายค่าเอนเอียงและความแปรปรวนของข้อมูลที่เป็นมูลเหตุสำคัญของการฟิตเกิน \n",
    "วิธีที่นิยมใช้แก้ปัญหาคือคือการทำเรกูลาร์ไรเซชันและดรอปเอาต์ การหยุดฝึกตั้งแต่ช่วงต้น \n",
    "การจัดการข้อมูลก่อนเริ่มต้นการฝึกช่วยทำให้การฝึกโมเดลทำได้ง่ายขึ้น คือการทำอินพุตให้เป็นบรรทัดฐาน \n",
    "และการกำหนดค่าเริ่มต้นของพารามิเตอร์การเรียนรู้ สำหรับการเลือกตัวหาค่าเหมาะที่สุดมีส่วนช่วยในการลดค่าเกรเดียนต์ \n",
    "ตั้งแต่วิธีการพื้นฐานคือ SGD ที่สามารถเพิ่มโมเมนตัม วิธีการ RMSprop และ Adam \n",
    "การปรับอัตราการเรียนรู้ในการฝึกทำได้ทั้งแบบเลือกค่าคงที่หรือปรับค่าอัตโนมัติ \n",
    "โดยทั่วไปจะให้ค่าลดลงตามจำนวนรอบการฝึก การทำกลุ่มให้เป็นบรรทัดฐานเป็นอีกวิธีการหนึ่งที่สามารถช่วยในการฝึกโมเดล\n",
    "\n",
    "จากการทดสอบโมเดล DNN พบว่ามีความแม่นยำในการจำแนกข้อมูลภาพไม่สูงมาก \n",
    "สถาปัตยกรรมที่เหมาะสมกับการใช้ในงานที่เกี่ยวข้องกับข้อมูลภาพคือ CNN ซึ่งเป็นเนื้อหาของบทที่ 4 \n",
    "ในส่วนต้นของบทกล่าวถึงการทำสังวัตนาการที่ช่วยในการดึงลักษณะเด่นของภาพ เช่นขอบของวัตถุ \n",
    "ซึ่งหัวใจสำคัญของสถาปัตยกรรม CNN คือการเพิ่มชั้นสังวัตนาการให้กับโครงข่ายเพื่อประสิทธิภาพในการจำแนกข้อมูลภาพได้ดีขึ้น \n",
    "โดยมักใช้งานร่วมกับชั้นพูลลิงที่สามารถลดขนาดของข้อมูลลง อย่างไรก็ตามโมเดล CNN \n",
    "ที่เพิ่มชั้นสังวัตนาการจำนวนมากทำให้มีความลึกมากและประสบปัญหาในการฝึก การใช้บล็อกส่วนตกค้างใน ResNets \n",
    "ช่วยบรรเทาอุปสรรคในการฝึกโมเดล ส่วนมอดูลอินเซปชันเป็นตัวช่วยสร้างคอขวดเพื่อลดจำนวนการดำเนินการทางคณิตศาสตร์ลงได้ \n",
    "เป็นองค์ประกอบหลักของโมเดลอินเซปชัน ในกรณีที่มีข้อมูลจำนวนไม่มากหรือไม่ต้องการฝึกโมเดลเป็นเวลานาน \n",
    "วิธีที่เรียกว่าการถ่ายโอนการเรียนรูู้ช่วยให้เราสามารถนำโมเดลที่ถูกพัฒนาและฝึกแล้วมาใช้ในปัญหาของเราได้ \n",
    "โดยแทนที่บางชั้นในส่วนท้ายของโมเดลและฝึกเฉพาะส่วนนั้น \n",
    "\n",
    "การใช้งานการเรียนรู้เชิงลึกเพื่อแก้ปัญหาที่เกี่ยวข้องกับข้อมูลลำดับเป็นอีกแนวทางหนึ่งที่ได้รับความสนใจอย่างมาก \n",
    "เช่นการประมวลผลภาษาธรรมชาติ การแปลภาษาโดยเครื่อง การกำเนิดบทกวีหรือดนตรี การจำแนกอารมณ์ของบทความ \n",
    "การสั่งงานโดยเสียง การวิเคราะห์ข้อมูลฐานเวลา ลักษณะงานเหล่านี้ต้องการการส่งผ่านข้อมูลสถานะตามขั้นเวลา \n",
    "ในบทที่ 5 เป็นการศึกษาโมเดลลำดับตั้งแต่สถาปัตยกรรมพื้นฐานเรียกว่า RNN จนถึงโมเดลที่มีพัฒนาให้มีความจำระยะยาว \n",
    "คือ GRU และ LSTM \n",
    "\n",
    "ภาคผนวก A รวบรวมหลักการและวิธีการที่สนับสนุนเนื้อหาหลักของหนังสือแต่มีรายละเอียดมากเกินกว่าจะแทรกในตัวบท \n",
    "ส่วนภาคผนวก B กล่าวถึงการติดตั้งซอฟต์แวร์ที่ใช้ในหนังสือ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 สรุปท้ายบท\n",
    "\n",
    "ในบทแรกนี้เป็นการกล่าวแนะนำการเรียนรู้เชิงลึก ซึ่งเป็นเซตย่อยของการเรียนรู้ของเครื่องและปัญญาประดิษฐ์ \n",
    "โดยสมรรถนะของฮาร์ดแวร์คอมพิวเตอร์ที่พัฒนาขึ้นอย่างต่อเนื่องผนวกกับปัญหาปัจจุบันที่มักเกี่ยวข้องกับข้อมูลขนาดใหญ่\n",
    "ทำให้โครงข่ายประสาทเทียมและการเรียนรู้เชิงลึกถูกนำมาใช้ได้อย่างมีประสิทธิภาพและประสบผลสำเร็จในหลายสาขา \n",
    "ในส่วนท้ายของบทนี้กล่าวถึงซอฟต์แวร์ที่ใช้เป็นกรอบการพัฒนา ซึ่งในหนังสือจะใช้ไลบรารี TF ซึ่งจากสถิติปัจจุบันพบว่า\n",
    "ได้รับความนิยมอย่างสูง "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## โจทย์ปัญหา\n",
    "\n",
    "1-1 จากตัวอย่าง 1.1 ทดลองเปลี่ยนฟังก์ชันในสมการ (1.1) เช่น $y = -3x+2$ สร้างแอเรย์อินพุตและเอาต์พุต \n",
    "10 ค่าเพื่อฝึกโมเดล ตรวจสอบผลการพยากรณ์\n",
    "\n",
    "1-2 ดัดแปลงโมเดลในตัวอย่าง 1.1 ให้สามารถพยากรณ์สมการ 2 ตัวแปรอิสระ เช่น $y = x_1 - 2x_2 + 4$\n",
    "\n",
    "1-3 จากตัวอย่าง 1.2 ปรับปรุงโมเดลโดยเพิ่มชั้น Conv2D() และ MaxPooling2D() อีกคู่หนึ่ง \n",
    "ฝึกโมเดลโดยใช้ข้อมูลเดิมและไฮเปอร์พารามิเตอร์เดิม ตรวจสอบความแม่นยำในการพยากรณ์ว่าดีขึ้นมากน้อยเพียงใด\n",
    "\n",
    "1-4 ทดสอบการสร้างโมเดลในตัวอย่าง 1.2 โดยใช้ API เชิงฟังก์ชัน\n",
    "\n",
    "1-5 จากโมเดลในหัวข้อ 1.5.4 หลังจากปิดกั้นการฝึกของชั้น conv2d_layer และ dense_layer1 แล้ว \n",
    "เขียนโค้ดเพื่อถอดชั้น dense_layer2 และ output_layer ออก แทนที่ด้วยชั้น output_layer ใหม่ที่เป็นการจำแนกทวิภาค\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/thumbnail?id=13bzT7Rmy3bzvE7TiS0yfQo94kpxMuipF\" alt=\"dewninja\"/>\n",
    "</p>\n",
    "<div align=\"center\">dew.ninja 2021</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
